{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04b197f",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b35c76f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1aa0208fdb142ec901439a7a4b8273d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c12308b7d6451c804dbaf60730b522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import re\n",
    "\n",
    "def get_vi_gsm8k_questions(split=\"train\") -> Dataset:\n",
    "    data = load_dataset('hllj/vi_gsm8k')[split] \n",
    "\n",
    "    def normalize_answer(example):\n",
    "        # Lo·∫°i b·ªè d·∫•u ph·∫©y trong s·ªë v√† chuy·ªÉn th√†nh d·∫°ng s·ªë nguy√™n\n",
    "        example['answer'] = re.sub(r'[^\\d]', '', example['answer'])\n",
    "        return example\n",
    "\n",
    "    data = data.map(normalize_answer) \n",
    "\n",
    "    data = data.map(lambda x: { \n",
    "        'answer': x['explanation'] + \"\\n### \" + x['answer'],\n",
    "    })  \n",
    "\n",
    "    return data  \n",
    "\n",
    "dataset = get_vi_gsm8k_questions(split = \"train\")\n",
    "test_dataset = get_vi_gsm8k_questions(split = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "522487d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'explanation', 'question', 'answer'],\n",
       "    num_rows: 7473\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfdf38a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'explanation', 'question', 'answer'],\n",
       "    num_rows: 1319\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd5df98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'explanation': 'Natalia ƒë√£ b√°n 24 k·∫πp trong th√°ng 5.\\nNatalia ƒë√£ b√°n t·ªïng c·ªông 72 k·∫πp trong th√°ng 4 v√† th√°ng 5.',\n",
       " 'question': 'Natalia ƒë√£ b√°n k·∫πp t√≥c cho 48 ng∆∞·ªùi b·∫°n c·ªßa c√¥ ·∫•y v√†o th√°ng 4, v√† sau ƒë√≥ c√¥ ·∫•y ƒë√£ b√°n n·ª≠a s·ªë l∆∞·ª£ng k·∫πp t√≥c ƒë√≥ v√†o th√°ng 5. Natalia ƒë√£ b√°n t·ªïng c·ªông bao nhi√™u k·∫πp t√≥c trong th√°ng 4 v√† th√°ng 5?',\n",
       " 'answer': 'Natalia ƒë√£ b√°n 24 k·∫πp trong th√°ng 5.\\nNatalia ƒë√£ b√°n t·ªïng c·ªông 72 k·∫πp trong th√°ng 4 v√† th√°ng 5.\\n### 72'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78766122",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770001e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.1: Fast Qwen2 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Ti SUPER. Num GPUs = 1. Max memory: 15.992 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"unsloth/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "model, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"cuda:0\",\n",
    "    dtype = torch.bfloat16,\n",
    "    max_seq_length=1536,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = 'left'\n",
    "# model.enable_input_require_grads() \n",
    "# tokenizer.padding_side  = 'left' # Must set to left because of flash attn 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a14f3676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω to√°n h·ªçc.\n",
      "H√£y suy nghƒ© c·∫©n th·∫≠n ƒë·ªÉ gi·∫£i b√†i to√°n ƒë∆∞·ª£c cung c·∫•p.\n",
      "Tr√¨nh b√†y t·ª´ng b∆∞·ªõc. Sau ƒë√≥ tr·∫£ l·ªùi theo c√∫ ph√°p:\n",
      "### number\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "C√≥ bao nhi√™u ch·ªØ 'r' trong t·ª´ 'waterrmelon' ?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "ƒê·ªÉ gi·∫£i b√†i to√°n n√†y, ch√∫ng ta s·∫Ω ki·ªÉm tra t·ª´ng ch·ªØ c√°i trong t·ª´ 'waterrmelon' xem c√≥ ch·ªØ 'r' kh√¥ng.\n",
      "\n",
      "1. ƒê·∫ßu ti√™n, ch√∫ng ta xem t·ª´ 'waterrmelon':\n",
      "   - 'w'\n",
      "   - 'a'\n",
      "   - 't'\n",
      "   - 'e'\n",
      "   - 'r'\n",
      "   - 'r'\n",
      "   - 'm'\n",
      "   - 'e'\n",
      "   - 'l'\n",
      "   - 'o'\n",
      "   - 'n'\n",
      "\n",
      "2. Trong t·ª´ tr√™n, ch√∫ng ta th·∫•y c√≥ hai ch·ªØ 'r'.\n",
      "\n",
      "V·∫≠y, s·ªë ch·ªØ 'r' trong t·ª´ 'waterrmelon' l√† 2.\n",
      "\n",
      "### 2<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "SYSTEM_PROMPT = \\\n",
    "\"\"\"B·∫°n l√† m·ªôt tr·ª£ l√Ω to√°n h·ªçc.\n",
    "H√£y suy nghƒ© c·∫©n th·∫≠n ƒë·ªÉ gi·∫£i b√†i to√°n ƒë∆∞·ª£c cung c·∫•p.\n",
    "Tr√¨nh b√†y t·ª´ng b∆∞·ªõc. Sau ƒë√≥ tr·∫£ l·ªùi theo c√∫ ph√°p:\n",
    "### number\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"C√≥ bao nhi√™u ch·ªØ 'r' trong t·ª´ 'waterrmelon' ?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=256,\n",
    "    streamer = text_streamer\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef9429",
   "metadata": {},
   "source": [
    "# Build QLoRA config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10ede17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.1 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 59,867,136 || all params: 3,145,805,824 || trainable%: 1.9031\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32, \n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, \n",
    "    bias = \"none\",    \n",
    "    use_gradient_checkpointing = \"unsloth\", \n",
    "    use_rslora = True,  \n",
    "    loftq_config = None, \n",
    ")\n",
    "\n",
    "print (model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cf582b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForCausalLM(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(151936, 2048, padding_idx=151654)\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=11008, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=11008, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "          )\n",
       "          (2-3): 2 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=11008, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=11008, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "          )\n",
       "          (4-29): 26 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=11008, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=11008, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "          )\n",
       "          (30): Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=11008, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=11008, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "          )\n",
       "          (31-35): 5 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=11008, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=11008, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777a967b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4635744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    # Extract fields for the entire batch\n",
    "    inputs = batch[\"question\"]\n",
    "    outputs = batch[\"answer\"]\n",
    "\n",
    "    processed_texts = []\n",
    "    for input_text, output in zip(inputs, outputs):\n",
    "        input_text = input_text.strip() if input_text else \"\"\n",
    "        output = output.strip()\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": input_text},\n",
    "            {\"role\": \"assistant\", \"content\": output}\n",
    "        ]\n",
    "\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            # add_generation_prompt=True # comment this for training\n",
    "        )\n",
    "        processed_texts.append(text)\n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad91f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collator for causal LM\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "response_template = \"<|im_start|>assistant\\n\"\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    tokenizer=tokenizer,\n",
    "    response_template=response_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbeee0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aaf2f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    # Paths & Datasets\n",
    "    output_dir=\"qwen-2.5-3b-instruct-math-qa\",    \n",
    "    \n",
    "    # Truncation \n",
    "    max_seq_length=1536,\n",
    "    \n",
    "    per_device_train_batch_size=6,       \n",
    "    per_device_eval_batch_size=6,\n",
    "    gradient_accumulation_steps=2,\n",
    "\n",
    "    # Optimization & LR Scheduling\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.05,\n",
    "    num_train_epochs=2,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=10,\n",
    "\n",
    "    # Evaluation / Checkpoint\n",
    "    eval_strategy=\"steps\",              \n",
    "    save_strategy=\"steps\",              \n",
    "    logging_strategy=\"steps\",\n",
    "    eval_steps=200,       \n",
    "    save_steps=200,\n",
    "    save_total_limit=1,\n",
    "\n",
    "    # Best‚Äëmodel selection\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    gradient_checkpointing=True,\n",
    "    optim =\"paged_adamw_8bit\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "516418f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a695286f474bf6957caa8c6bcde0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bffc4c01491421b85c9b7da55f8bd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,                         \n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    args=sft_config,                     \n",
    "    processing_class=tokenizer,\n",
    "    formatting_func=preprocess_batch,\n",
    "    data_collator=data_collator,\n",
    "    dataset_num_proc=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f018fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 7,473 | Num Epochs = 2 | Total steps = 1,246\n",
      "O^O/ \\_/ \\    Batch size per device = 6 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (6 x 2 x 1) = 12\n",
      " \"-____-\"     Trainable parameters = 59,867,136/3,000,000,000 (2.00% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1246' max='1246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1246/1246 34:52, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.447700</td>\n",
       "      <td>0.599701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.535400</td>\n",
       "      <td>0.574737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.583100</td>\n",
       "      <td>0.559330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.572599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>0.566545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.383000</td>\n",
       "      <td>0.565581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but Qwen2ForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
     ]
    }
   ],
   "source": [
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b2d6261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 00:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = trainer.evaluate(trainer.eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da889df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7494996062448478"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate perplexity\n",
    "import math\n",
    "perplexity = math.exp(metrics[\"eval_loss\"])\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77b58dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9230ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push to hub\n",
    "trainer.push_to_hub(\"binhphap5/qwen-2.5-3b-instruct-math-qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe82153a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "B·∫°n l√† m·ªôt tr·ª£ l√Ω to√°n h·ªçc.\n",
      "H√£y suy nghƒ© c·∫©n th·∫≠n ƒë·ªÉ gi·∫£i b√†i to√°n ƒë∆∞·ª£c cung c·∫•p.\n",
      "Tr√¨nh b√†y t·ª´ng b∆∞·ªõc. Sau ƒë√≥ tr·∫£ l·ªùi theo c√∫ ph√°p:\n",
      "### number\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Lan c√≥ 2 c√¢y b√∫t, h√¥m sau Lan mua th√™m 1 c√¢y b√∫t n·ªØa, v·∫≠y Lan c√≥ t·ªïng c·ªông bao nhi√™u c√¢y b√∫t?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Lan c√≥ 2 c√¢y b√∫t + 1 c√¢y b√∫t = 3 c√¢y b√∫t.\n",
      "### 3<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "input = 'Lan c√≥ 2 c√¢y b√∫t, h√¥m sau Lan mua th√™m 1 c√¢y b√∫t n·ªØa, v·∫≠y Lan c√≥ t·ªïng c·ªông bao nhi√™u c√¢y b√∫t?'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": input},\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True # comment this for training\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "acb2011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f535dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.1: Fast Qwen2 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Ti SUPER. Num GPUs = 1. Max memory: 15.992 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.1 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"qwen-2.5-3b-instruct-math-qa/checkpoint-2400\"\n",
    "\n",
    "model, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"cuda:0\",\n",
    "    dtype = torch.bfloat16,\n",
    "    max_seq_length=2048,\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = 'left'\n",
    "# model.enable_input_require_grads() \n",
    "# tokenizer.padding_side  = 'left' # Must set to left because of flash attn 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda1ea7f",
   "metadata": {},
   "source": [
    "# Batch generation helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3c37f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import re\n",
    "\n",
    "def extract_reasoning_and_answer(text):\n",
    "    \"\"\"\n",
    "    Given the full output text, extract the reasoning and the final answer robustly.\n",
    "    Handles noisy generation after the answer.\n",
    "    \"\"\"\n",
    "    answer_markers = [\"###\"]\n",
    "    \n",
    "    marker_found = None\n",
    "    for marker in answer_markers:\n",
    "        if marker in text:\n",
    "            marker_found = marker\n",
    "            break\n",
    "    \n",
    "    if marker_found:\n",
    "        parts = text.split(marker_found, 1)\n",
    "        reasoning = parts[0].strip()\n",
    "        answer = parts[1].strip()\n",
    "                \n",
    "    else:\n",
    "        # fallback n·∫øu kh√¥ng t√¨m th·∫•y marker\n",
    "        reasoning = text.strip()\n",
    "        answer = \"\"\n",
    "    \n",
    "    return reasoning, answer\n",
    "\n",
    "def generate_batch_responses(input_texts, model, tokenizer, batch_size=20, max_length=768):\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    all_outputs = []\n",
    "    for i in tqdm(range(0, len(input_texts), batch_size), desc=\"Generating responses\"):\n",
    "        batch_inputs = input_texts[i:i + batch_size]\n",
    "        \n",
    "        # Apply chat template for each input in the batch\n",
    "        batch_prompts = []\n",
    "        for text in batch_inputs:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ]\n",
    "            prompt = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True  # Comment this for training\n",
    "            )\n",
    "            batch_prompts.append(prompt)\n",
    "        \n",
    "        # Tokenize all prompts in the batch\n",
    "        batch_encodings = tokenizer(\n",
    "            batch_prompts, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True\n",
    "        ).to(model.device)\n",
    "        \n",
    "        # Generate for all inputs in batch\n",
    "        with torch.no_grad():\n",
    "            FastLanguageModel.for_inference(model)\n",
    "            outputs = model.generate(\n",
    "                **batch_encodings,\n",
    "                max_new_tokens=max_length,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.95,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        \n",
    "        # Decode all outputs\n",
    "        decoded_outputs = [\n",
    "            tokenizer.decode(output, skip_special_tokens=True)\n",
    "            for output in outputs\n",
    "        ]\n",
    "        \n",
    "        # Extract responses\n",
    "        responses = [\n",
    "            output.split(\"\\nassistant\\n\")[-1].strip()\n",
    "            for output in decoded_outputs\n",
    "        ]\n",
    "\n",
    "        # Extract reasoning v√† answer\n",
    "        for response in responses:\n",
    "            reasoning, answer = extract_reasoning_and_answer(response)\n",
    "            all_outputs.append({\n",
    "                \"reasoning\": reasoning,\n",
    "                \"answer\": answer,\n",
    "                \"raw\": response\n",
    "            })\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "14218dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'left'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab9b9ed",
   "metadata": {},
   "source": [
    "# Calculate rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cbdb7db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [02:36<00:00, 31.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 3 examples:\n",
      "\n",
      "Input: V·ªãt c·ªßa Janet ƒë·∫ª ƒë∆∞·ª£c 16 qu·∫£ tr·ª©ng m·ªói ng√†y. C√¥ ·∫•y ƒÉn 3 qu·∫£ v√†o b·ªØa s√°ng v√† n∆∞·ªõng b√°nh muffin cho b·∫°n b√® m·ªói ng√†y v·ªõi 4 qu·∫£. C√¥ ·∫•y b√°n s·ªë tr·ª©ng c√≤n l·∫°i t·∫°i ch·ª£ n√¥ng s·∫£n h√†ng ng√†y v·ªõi gi√° $2 m·ªói qu·∫£ tr·ª©ng v·ªãt t∆∞∆°i. C√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c bao nhi√™u ƒë√¥ la m·ªói ng√†y t·∫°i ch·ª£ n√¥ng s·∫£n?\n",
      "Prediction Reasoning: ƒê·∫ßu ti√™n, ch√∫ng ta t√≠nh s·ªë qu·∫£ tr·ª©ng m√† c√¥ ·∫•y gi·ªØ l·∫°i m·ªói ng√†y b·∫±ng c√°ch tr·ª´ s·ªë qu·∫£ tr·ª©ng c√¥ ·∫•y ƒë√£ ƒÉn v√† s·ªë qu·∫£ tr·ª©ng c√¥ ·∫•y l√†m b√°nh t·ª´ t·ªïng s·ªë tr·ª©ng c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c: 16 qu·∫£ tr·ª©ng - 3 qu·∫£ tr·ª©ng - 4 qu·∫£ tr·ª©ng = 9 qu·∫£ tr·ª©ng. Ti·∫øp theo, ch√∫ng ta t√≠nh s·ªë ti·ªÅn c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c b·∫±ng c√°ch nh√¢n s·ªë qu·∫£ tr·ª©ng c√¥ ·∫•y gi·ªØ l·∫°i v·ªõi gi√° c·ªßa m·ªói qu·∫£ tr·ª©ng: 9 qu·∫£ tr·ª©ng * $2/qu·∫£ tr·ª©ng = $18.\n",
      "Prediction Answer: 18\n",
      "Reference: Janet b√°n 9 qu·∫£ tr·ª©ng v·ªãt m·ªói ng√†y.\n",
      "C√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c 18 ƒë√¥ la m·ªói ng√†y t·∫°i ch·ª£ n√¥ng s·∫£n.\n",
      "### 18\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: M·ªôt chi·∫øc √°o cho√†ng c·∫ßn 2 cu·ªôn s·ª£i m√†u xanh v√† m·ªôt n·ª≠a s·ªë ƒë√≥ l√† s·ª£i m√†u tr·∫Øng. T·ªïng c·ªông c·∫ßn bao nhi√™u cu·ªôn s·ª£i?\n",
      "Prediction Reasoning: ƒê·∫ßu ti√™n, t√≠nh s·ªë cu·ªôn s·ª£i m√†u tr·∫Øng: 2 cu·ªôn s·ª£i / 2 = 1 cu·ªôn s·ª£i\n",
      "Sau ƒë√≥, c·ªông hai s·ªë l∆∞·ª£ng ƒë√≥ ƒë·ªÉ t√¨m t·ªïng s·ªë cu·ªôn s·ª£i: 1 cu·ªôn s·ª£i + 2 cu·ªôn s·ª£i = 3 cu·ªôn s·ª£i\n",
      "Prediction Answer: 3\n",
      "Reference: C·∫ßn 2/2=1 cu·ªôn s·ª£i m√†u tr·∫Øng.\n",
      "V√¨ v·∫≠y t·ªïng s·ªë l∆∞·ª£ng v·∫£i l√† 2+1=3 cu·ªôn v·∫£i.\n",
      "### 3\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: Josh quy·∫øt ƒë·ªãnh th·ª≠ s·ª©c v·ªõi vi·ªác mua b√°n nh√†. Anh ·∫•y mua m·ªôt cƒÉn nh√† v·ªõi gi√° $80,000 v√† sau ƒë√≥ chi th√™m $50,000 ƒë·ªÉ s·ª≠a ch·ªØa. Vi·ªác s·ª≠a ch·ªØa n√†y ƒë√£ l√†m tƒÉng gi√° tr·ªã c·ªßa cƒÉn nh√† l√™n 150%. Anh ·∫•y ƒë√£ ki·∫øm ƒë∆∞·ª£c bao nhi√™u l·ª£i nhu·∫≠n?\n",
      "Prediction Reasoning: Gi√° tr·ªã c·ªßa ng√¥i nh√† ƒë√£ tƒÉng th√™m 150%, t·ª©c l√† $120,000 (t√≠nh t·ª´ $80,000 ban ƒë·∫ßu).\n",
      "V·∫≠y gi√° tr·ªã hi·ªán t·∫°i c·ªßa ng√¥i nh√† l√† $200,000.\n",
      "Do ƒë√≥, l·ª£i nhu·∫≠n c·ªßa Josh l√† $120,000.\n",
      "Prediction Answer: 120000\n",
      "Reference: Chi ph√≠ c·ªßa cƒÉn nh√† v√† c√°c c√¥ng vi·ªác s·ª≠a ch·ªØa l√† 80.000 + 50.000 = 130.000 ƒë√¥ la.\n",
      "Anh ta tƒÉng gi√° tr·ªã c·ªßa cƒÉn nh√† l√™n 80.000 * 1,5 = 120.000 ƒë√¥ la.\n",
      "V√¨ v·∫≠y, gi√° tr·ªã m·ªõi c·ªßa cƒÉn nh√† l√† 120.000 + 80.000 = 200.000 ƒë√¥ la.\n",
      "V√¨ v·∫≠y, anh ta ƒë√£ ki·∫øm ƒë∆∞·ª£c l·ª£i nhu·∫≠n l√† 200.000 - 130.000 = 70.000 ƒë√¥ la.\n",
      "### 70000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the first 100 samples from test dataset\n",
    "test_sample = test_dataset.select(range(100))\n",
    "\n",
    "# Extract validation inputs and references\n",
    "val_inputs = [example[\"question\"] for example in test_sample]\n",
    "\n",
    "references = [example[\"answer\"] for example in test_sample]\n",
    "ref_reasonings = [example[\"explanation\"] for example in test_sample]\n",
    "\n",
    "# Generate predictions with batch processing\n",
    "print(\"Generating predictions...\")\n",
    "predictions = generate_batch_responses(val_inputs, model, tokenizer)\n",
    "\n",
    "# Example\n",
    "print(\"\\nFirst 3 examples:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nInput: {val_inputs[i]}\")\n",
    "    print(f\"Prediction Reasoning: {predictions[i]['reasoning']}\")\n",
    "    print(f\"Prediction Answer: {predictions[i]['answer']}\")\n",
    "    print(f\"Reference: {references[i]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e90956f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'reasoning': 'ƒê·∫ßu ti√™n, ch√∫ng ta t√≠nh s·ªë qu·∫£ tr·ª©ng m√† c√¥ ·∫•y gi·ªØ l·∫°i m·ªói ng√†y b·∫±ng c√°ch tr·ª´ s·ªë qu·∫£ tr·ª©ng c√¥ ·∫•y ƒë√£ ƒÉn v√† s·ªë qu·∫£ tr·ª©ng c√¥ ·∫•y l√†m b√°nh t·ª´ t·ªïng s·ªë tr·ª©ng c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c: 16 qu·∫£ tr·ª©ng - 3 qu·∫£ tr·ª©ng - 4 qu·∫£ tr·ª©ng = 9 qu·∫£ tr·ª©ng. Ti·∫øp theo, ch√∫ng ta t√≠nh s·ªë ti·ªÅn c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c b·∫±ng c√°ch nh√¢n s·ªë qu·∫£ tr·ª©ng c√¥ ·∫•y gi·ªØ l·∫°i v·ªõi gi√° c·ªßa m·ªói qu·∫£ tr·ª©ng: 9 qu·∫£ tr·ª©ng * $2/qu·∫£ tr·ª©ng = $18.',\n",
       "  'answer': '18',\n",
       "  'raw': 'ƒê·∫ßu ti√™n, ch√∫ng ta t√≠nh s·ªë qu·∫£ tr·ª©ng m√† c√¥ ·∫•y gi·ªØ l·∫°i m·ªói ng√†y b·∫±ng c√°ch tr·ª´ s·ªë qu·∫£ tr·ª©ng c√¥ ·∫•y ƒë√£ ƒÉn v√† s·ªë qu·∫£ tr·ª©ng c√¥ ·∫•y l√†m b√°nh t·ª´ t·ªïng s·ªë tr·ª©ng c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c: 16 qu·∫£ tr·ª©ng - 3 qu·∫£ tr·ª©ng - 4 qu·∫£ tr·ª©ng = 9 qu·∫£ tr·ª©ng. Ti·∫øp theo, ch√∫ng ta t√≠nh s·ªë ti·ªÅn c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c b·∫±ng c√°ch nh√¢n s·ªë qu·∫£ tr·ª©ng c√¥ ·∫•y gi·ªØ l·∫°i v·ªõi gi√° c·ªßa m·ªói qu·∫£ tr·ª©ng: 9 qu·∫£ tr·ª©ng * $2/qu·∫£ tr·ª©ng = $18.\\n### 18'},\n",
       " {'reasoning': 'ƒê·∫ßu ti√™n, t√≠nh s·ªë cu·ªôn s·ª£i m√†u tr·∫Øng: 2 cu·ªôn s·ª£i / 2 = 1 cu·ªôn s·ª£i\\nSau ƒë√≥, c·ªông hai s·ªë l∆∞·ª£ng ƒë√≥ ƒë·ªÉ t√¨m t·ªïng s·ªë cu·ªôn s·ª£i: 1 cu·ªôn s·ª£i + 2 cu·ªôn s·ª£i = 3 cu·ªôn s·ª£i',\n",
       "  'answer': '3',\n",
       "  'raw': 'ƒê·∫ßu ti√™n, t√≠nh s·ªë cu·ªôn s·ª£i m√†u tr·∫Øng: 2 cu·ªôn s·ª£i / 2 = 1 cu·ªôn s·ª£i\\nSau ƒë√≥, c·ªông hai s·ªë l∆∞·ª£ng ƒë√≥ ƒë·ªÉ t√¨m t·ªïng s·ªë cu·ªôn s·ª£i: 1 cu·ªôn s·ª£i + 2 cu·ªôn s·ª£i = 3 cu·ªôn s·ª£i\\n### 3'},\n",
       " {'reasoning': 'Gi√° tr·ªã c·ªßa ng√¥i nh√† ƒë√£ tƒÉng th√™m 150%, t·ª©c l√† $120,000 (t√≠nh t·ª´ $80,000 ban ƒë·∫ßu).\\nV·∫≠y gi√° tr·ªã hi·ªán t·∫°i c·ªßa ng√¥i nh√† l√† $200,000.\\nDo ƒë√≥, l·ª£i nhu·∫≠n c·ªßa Josh l√† $120,000.',\n",
       "  'answer': '120000',\n",
       "  'raw': 'Gi√° tr·ªã c·ªßa ng√¥i nh√† ƒë√£ tƒÉng th√™m 150%, t·ª©c l√† $120,000 (t√≠nh t·ª´ $80,000 ban ƒë·∫ßu).\\nV·∫≠y gi√° tr·ªã hi·ªán t·∫°i c·ªßa ng√¥i nh√† l√† $200,000.\\nDo ƒë√≥, l·ª£i nhu·∫≠n c·ªßa Josh l√† $120,000.\\n### 120000'},\n",
       " {'reasoning': 'Anh ta ch·∫°y 3*60=180 m√©t m·ªói l·∫ßn ch·∫°y\\nV·∫≠y t·ªïng c·ªông anh ta ch·∫°y 180*3=540 m√©t m·ªói tu·∫ßn',\n",
       "  'answer': '540',\n",
       "  'raw': 'Anh ta ch·∫°y 3*60=180 m√©t m·ªói l·∫ßn ch·∫°y\\nV·∫≠y t·ªïng c·ªông anh ta ch·∫°y 180*3=540 m√©t m·ªói tu·∫ßn\\n### 540'},\n",
       " {'reasoning': 'Sau bu·ªïi s√°ng, t·ªïng s·ªë c·ªëc th·ª©c ƒÉn m√† Wendi ƒë√£ cho g√† c·ªßa c√¥ ·∫•y l√† 15 + 25 = 40 c·ªëc.\\nV√¨ v·∫≠y, 20 con g√† c·ªßa Wendi s·∫Ω nh·∫≠n ƒë∆∞·ª£c 40/3 = 13,333... c·ªëc th·ª©c ƒÉn m·ªói con g√† v√†o b·ªØa ƒÉn cu·ªëi c√πng c·ªßa ng√†y. V√¨ 13,333... kh√¥ng ph·∫£i l√† m·ªôt s·ªë nguy√™n, n√™n ch√∫ng ta s·∫Ω l·∫•y gi√° tr·ªã g·∫ßn nh·∫•t l√† 13 c·ªëc th·ª©c ƒÉn m·ªói con g√† v√†o b·ªØa ƒÉn cu·ªëi c√πng c·ªßa ng√†y.\\nDo ƒë√≥, t·ªïng s·ªë c·ªëc th·ª©c ƒÉn m√† 20 con g√† c·ªßa Wendi s·∫Ω nh·∫≠n ƒë∆∞·ª£c v√†o b·ªØa ƒÉn cu·ªëi c√πng c·ªßa ng√†y l√† 13 * 20 = 260 c·ªëc th·ª©c ƒÉn.',\n",
       "  'answer': '260',\n",
       "  'raw': 'Sau bu·ªïi s√°ng, t·ªïng s·ªë c·ªëc th·ª©c ƒÉn m√† Wendi ƒë√£ cho g√† c·ªßa c√¥ ·∫•y l√† 15 + 25 = 40 c·ªëc.\\nV√¨ v·∫≠y, 20 con g√† c·ªßa Wendi s·∫Ω nh·∫≠n ƒë∆∞·ª£c 40/3 = 13,333... c·ªëc th·ª©c ƒÉn m·ªói con g√† v√†o b·ªØa ƒÉn cu·ªëi c√πng c·ªßa ng√†y. V√¨ 13,333... kh√¥ng ph·∫£i l√† m·ªôt s·ªë nguy√™n, n√™n ch√∫ng ta s·∫Ω l·∫•y gi√° tr·ªã g·∫ßn nh·∫•t l√† 13 c·ªëc th·ª©c ƒÉn m·ªói con g√† v√†o b·ªØa ƒÉn cu·ªëi c√πng c·ªßa ng√†y.\\nDo ƒë√≥, t·ªïng s·ªë c·ªëc th·ª©c ƒÉn m√† 20 con g√† c·ªßa Wendi s·∫Ω nh·∫≠n ƒë∆∞·ª£c v√†o b·ªØa ƒÉn cu·ªëi c√πng c·ªßa ng√†y l√† 13 * 20 = 260 c·ªëc th·ª©c ƒÉn.\\n### 260'},\n",
       " {'reasoning': 'Gi√° c·ªßa ly th·ª© hai s·∫Ω l√† $3 (t√≠nh t·ª´ 60% c·ªßa $5). V·∫≠y gi√° c·ªßa 16 ly s·∫Ω l√† $72 (t√≠nh t·ª´ $5 x 16).',\n",
       "  'answer': '72',\n",
       "  'raw': 'Gi√° c·ªßa ly th·ª© hai s·∫Ω l√† $3 (t√≠nh t·ª´ 60% c·ªßa $5). V·∫≠y gi√° c·ªßa 16 ly s·∫Ω l√† $72 (t√≠nh t·ª´ $5 x 16).\\n### 72'},\n",
       " {'reasoning': 'Charleston c√≥ 80 con c·ª´u (4 nh√¢n 20).\\nToulouse c√≥ 160 con c·ª´u (2 nh√¢n 80).\\nT·ªïng c·ªông, h·ªç c√≥ 260 con c·ª´u (20 c·ªông v·ªõi 80 c·ªông v·ªõi 160).',\n",
       "  'answer': '260',\n",
       "  'raw': 'Charleston c√≥ 80 con c·ª´u (4 nh√¢n 20).\\nToulouse c√≥ 160 con c·ª´u (2 nh√¢n 80).\\nT·ªïng c·ªông, h·ªç c√≥ 260 con c·ª´u (20 c·ªông v·ªõi 80 c·ªông v·ªõi 160).\\n### 260'},\n",
       " {'reasoning': 'ƒê·∫ßu ti√™n t√¨m t·ªïng s·ªë byte trong t·ªáp: 200 GB * 1000 MB/GB = 200000 MB\\nSau ƒë√≥ chia s·ªë ƒë√≥ cho t·ªëc ƒë·ªô t·∫£i xu·ªëng c·ªßa Carla: 200000 MB / 2 MB/min = 100000 min\\nTi·∫øp theo nh√¢n s·ªë ƒë√≥ v·ªõi t·ª∑ l·ªá ph·∫ßn trƒÉm m√† Carla ƒë√£ t·∫£i: 100000 min * .4 = 40000 min\\nB√¢y gi·ªù th√™m th·ªùi gian kh·ªüi ƒë·ªông l·∫ßn ƒë·∫ßu: 40000 min + 20 min = 40020 min\\nSau ƒë√≥ th√™m th·ªùi gian kh·ªüi ƒë·ªông sau ƒë√≥: 40020 min + 40020 min = 80040 min',\n",
       "  'answer': '80040',\n",
       "  'raw': 'ƒê·∫ßu ti√™n t√¨m t·ªïng s·ªë byte trong t·ªáp: 200 GB * 1000 MB/GB = 200000 MB\\nSau ƒë√≥ chia s·ªë ƒë√≥ cho t·ªëc ƒë·ªô t·∫£i xu·ªëng c·ªßa Carla: 200000 MB / 2 MB/min = 100000 min\\nTi·∫øp theo nh√¢n s·ªë ƒë√≥ v·ªõi t·ª∑ l·ªá ph·∫ßn trƒÉm m√† Carla ƒë√£ t·∫£i: 100000 min * .4 = 40000 min\\nB√¢y gi·ªù th√™m th·ªùi gian kh·ªüi ƒë·ªông l·∫ßn ƒë·∫ßu: 40000 min + 20 min = 40020 min\\nSau ƒë√≥ th√™m th·ªùi gian kh·ªüi ƒë·ªông sau ƒë√≥: 40020 min + 40020 min = 80040 min\\n### 80040'},\n",
       " {'reasoning': 'Anh ta l√°i xe 180 d·∫∑m trong 3 gi·ªù v·ªõi v·∫≠n t·ªëc 60 d·∫∑m m·ªói gi·ªù.\\nAnh ta ƒëi ƒë∆∞·ª£c 30 d·∫∑m trong 2 gi·ªù ƒë·∫ßu ti√™n.\\nAnh ta l√°i xe v·ªõi v·∫≠n t·ªëc 80 d·∫∑m m·ªói gi·ªù trong 2 gi·ªù ti·∫øp theo.\\nV√¨ v·∫≠y, anh ta l√°i xe ƒë∆∞·ª£c 160 d·∫∑m trong 2 gi·ªù cu·ªëi c√πng.\\nDo ƒë√≥, t·ªïng kho·∫£ng c√°ch l√°i xe c·ªßa anh ta l√† 180 + 30 + 160 = 370 d·∫∑m.',\n",
       "  'answer': '370',\n",
       "  'raw': 'Anh ta l√°i xe 180 d·∫∑m trong 3 gi·ªù v·ªõi v·∫≠n t·ªëc 60 d·∫∑m m·ªói gi·ªù.\\nAnh ta ƒëi ƒë∆∞·ª£c 30 d·∫∑m trong 2 gi·ªù ƒë·∫ßu ti√™n.\\nAnh ta l√°i xe v·ªõi v·∫≠n t·ªëc 80 d·∫∑m m·ªói gi·ªù trong 2 gi·ªù ti·∫øp theo.\\nV√¨ v·∫≠y, anh ta l√°i xe ƒë∆∞·ª£c 160 d·∫∑m trong 2 gi·ªù cu·ªëi c√πng.\\nDo ƒë√≥, t·ªïng kho·∫£ng c√°ch l√°i xe c·ªßa anh ta l√† 180 + 30 + 160 = 370 d·∫∑m.\\n### 370'},\n",
       " {'reasoning': 'Eliza ki·∫øm ƒë∆∞·ª£c $10/gi·ªù cho 40 gi·ªù l√†m vi·ªác, v√¨ v·∫≠y c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c 10*40 = $400.\\nC√¥ ·∫•y c≈©ng ki·∫øm ƒë∆∞·ª£c th√™m ti·ªÅn khi l√†m vi·ªác th√™m gi·ªù, t·ªïng c·ªông l√† 1.2*$10 = $12 m·ªói gi·ªù.\\nN·∫øu c√¥ ·∫•y l√†m vi·ªác th√™m 5 gi·ªù, c√¥ ·∫•y s·∫Ω ki·∫øm ƒë∆∞·ª£c th√™m 12*5 = $60.\\nTrong tu·∫ßn n√†y, t·ªïng thu nh·∫≠p c·ªßa Eliza l√† $400+$60 = $460.',\n",
       "  'answer': '460',\n",
       "  'raw': 'Eliza ki·∫øm ƒë∆∞·ª£c $10/gi·ªù cho 40 gi·ªù l√†m vi·ªác, v√¨ v·∫≠y c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c 10*40 = $400.\\nC√¥ ·∫•y c≈©ng ki·∫øm ƒë∆∞·ª£c th√™m ti·ªÅn khi l√†m vi·ªác th√™m gi·ªù, t·ªïng c·ªông l√† 1.2*$10 = $12 m·ªói gi·ªù.\\nN·∫øu c√¥ ·∫•y l√†m vi·ªác th√™m 5 gi·ªù, c√¥ ·∫•y s·∫Ω ki·∫øm ƒë∆∞·ª£c th√™m 12*5 = $60.\\nTrong tu·∫ßn n√†y, t·ªïng thu nh·∫≠p c·ªßa Eliza l√† $400+$60 = $460.\\n### 460'},\n",
       " {'reasoning': 'Th√°ng th·ª© 2: 60*3=180 l∆∞·ª£t t·∫£i\\nTh√°ng th·ª© 3: 180(.7)=126 l∆∞·ª£t t·∫£i\\nT·ªïng: 60+180+126=366 l∆∞·ª£t t·∫£i',\n",
       "  'answer': '366',\n",
       "  'raw': 'Th√°ng th·ª© 2: 60*3=180 l∆∞·ª£t t·∫£i\\nTh√°ng th·ª© 3: 180(.7)=126 l∆∞·ª£t t·∫£i\\nT·ªïng: 60+180+126=366 l∆∞·ª£t t·∫£i\\n### 366'},\n",
       " {'reasoning': 'ƒê·∫ßu ti√™n t√¨m t·ªïng chi ph√≠ c·ªßa nh·ªØng chi·∫øc b√°nh r√°n: 3 t√° b√°nh r√°n * $68/t√° = $198\\nSau ƒë√≥ t√¨m t·ªïng chi ph√≠ c·ªßa nh·ªØng chi·∫øc b√°nh cupcake: 2 t√° b√°nh cupcake * $80/t√° = $160\\nTi·∫øp theo t√¨m t·ªïng chi ph√≠ c·ªßa nh·ªØng chi·∫øc b√°nh ph√¥ mai: 6 t√° b√°nh ph√¥ mai * $55/t√° = $330\\nB√¢y gi·ªù c·ªông t·∫•t c·∫£ c√°c s·ªë ti·ªÅn ƒë√≥ ƒë·ªÉ t√¨m t·ªïng chi ph√≠: $198 + $160 + $330 = $688',\n",
       "  'answer': '688',\n",
       "  'raw': 'ƒê·∫ßu ti√™n t√¨m t·ªïng chi ph√≠ c·ªßa nh·ªØng chi·∫øc b√°nh r√°n: 3 t√° b√°nh r√°n * $68/t√° = $198\\nSau ƒë√≥ t√¨m t·ªïng chi ph√≠ c·ªßa nh·ªØng chi·∫øc b√°nh cupcake: 2 t√° b√°nh cupcake * $80/t√° = $160\\nTi·∫øp theo t√¨m t·ªïng chi ph√≠ c·ªßa nh·ªØng chi·∫øc b√°nh ph√¥ mai: 6 t√° b√°nh ph√¥ mai * $55/t√° = $330\\nB√¢y gi·ªù c·ªông t·∫•t c·∫£ c√°c s·ªë ti·ªÅn ƒë√≥ ƒë·ªÉ t√¨m t·ªïng chi ph√≠: $198 + $160 + $330 = $688\\n### 688'},\n",
       " {'reasoning': 'Anh ·∫•y c·∫ßn $90 v√† m·ªói nƒÉm n√≥ s·∫Ω s·∫£n xu·∫•t ƒë∆∞·ª£c 7 qu·∫£ chanh v·ªõi gi√° $1.5 m·ªói qu·∫£ n√™n m·ªói nƒÉm anh ·∫•y s·∫Ω ki·∫øm ƒë∆∞·ª£c 7*1.5 = $10.5. Anh ·∫•y c·∫ßn 90 v√† anh ·∫•y ki·∫øm ƒë∆∞·ª£c $10.5 m·ªói nƒÉm n√™n anh ·∫•y s·∫Ω m·∫•t 90/10.5 = 8 nƒÉm ƒë·ªÉ b·∫Øt ƒë·∫ßu ki·∫øm ƒë∆∞·ª£c l·ª£i nhu·∫≠n.',\n",
       "  'answer': '8',\n",
       "  'raw': 'Anh ·∫•y c·∫ßn $90 v√† m·ªói nƒÉm n√≥ s·∫Ω s·∫£n xu·∫•t ƒë∆∞·ª£c 7 qu·∫£ chanh v·ªõi gi√° $1.5 m·ªói qu·∫£ n√™n m·ªói nƒÉm anh ·∫•y s·∫Ω ki·∫øm ƒë∆∞·ª£c 7*1.5 = $10.5. Anh ·∫•y c·∫ßn 90 v√† anh ·∫•y ki·∫øm ƒë∆∞·ª£c $10.5 m·ªói nƒÉm n√™n anh ·∫•y s·∫Ω m·∫•t 90/10.5 = 8 nƒÉm ƒë·ªÉ b·∫Øt ƒë·∫ßu ki·∫øm ƒë∆∞·ª£c l·ª£i nhu·∫≠n.\\n### 8'},\n",
       " {'reasoning': 'Melanie b√°n ƒë∆∞·ª£c m·ªôt ph·∫ßn ba s·ªë l∆∞·ª£ng m√°y h√∫t b·ª•i trong nh√† m√†u xanh, v√¨ v·∫≠y c√≤n l·∫°i 1-1/3 = 2/3 s·ªë l∆∞·ª£ng ban ƒë·∫ßu.\\nC√¥ ·∫•y b√°n ƒë∆∞·ª£c hai m√°y h√∫t b·ª•i nhi·ªÅu h∆°n s·ªë l∆∞·ª£ng trong nh√† m√†u ƒë·ªè, v√¨ v·∫≠y c√≤n l·∫°i 1-1-2 = -2/3 s·ªë l∆∞·ª£ng ban ƒë·∫ßu.\\nS·ªë l∆∞·ª£ng m√°y h√∫t b·ª•i m√† c√¥ ·∫•y b√°n ƒë∆∞·ª£c ·ªü nh√† m√†u cam l√† 1/2 s·ªë l∆∞·ª£ng ban ƒë·∫ßu, v√¨ v·∫≠y c√≤n l·∫°i 1-1/2 = 1/2 s·ªë l∆∞·ª£ng ban ƒë·∫ßu.\\nV√¨ c√¥ ·∫•y c√≤n l·∫°i 5 m√°y h√∫t b·ª•i, ƒëi·ªÅu n√†y t∆∞∆°ng ƒë∆∞∆°ng v·ªõi 1/2 s·ªë l∆∞·ª£ng ban ƒë·∫ßu, v√¨ v·∫≠y 5*2 = 10 m√°y h√∫t b·ª•i l√† s·ªë l∆∞·ª£ng ban ƒë·∫ßu.',\n",
       "  'answer': '10',\n",
       "  'raw': 'Melanie b√°n ƒë∆∞·ª£c m·ªôt ph·∫ßn ba s·ªë l∆∞·ª£ng m√°y h√∫t b·ª•i trong nh√† m√†u xanh, v√¨ v·∫≠y c√≤n l·∫°i 1-1/3 = 2/3 s·ªë l∆∞·ª£ng ban ƒë·∫ßu.\\nC√¥ ·∫•y b√°n ƒë∆∞·ª£c hai m√°y h√∫t b·ª•i nhi·ªÅu h∆°n s·ªë l∆∞·ª£ng trong nh√† m√†u ƒë·ªè, v√¨ v·∫≠y c√≤n l·∫°i 1-1-2 = -2/3 s·ªë l∆∞·ª£ng ban ƒë·∫ßu.\\nS·ªë l∆∞·ª£ng m√°y h√∫t b·ª•i m√† c√¥ ·∫•y b√°n ƒë∆∞·ª£c ·ªü nh√† m√†u cam l√† 1/2 s·ªë l∆∞·ª£ng ban ƒë·∫ßu, v√¨ v·∫≠y c√≤n l·∫°i 1-1/2 = 1/2 s·ªë l∆∞·ª£ng ban ƒë·∫ßu.\\nV√¨ c√¥ ·∫•y c√≤n l·∫°i 5 m√°y h√∫t b·ª•i, ƒëi·ªÅu n√†y t∆∞∆°ng ƒë∆∞∆°ng v·ªõi 1/2 s·ªë l∆∞·ª£ng ban ƒë·∫ßu, v√¨ v·∫≠y 5*2 = 10 m√°y h√∫t b·ª•i l√† s·ªë l∆∞·ª£ng ban ƒë·∫ßu.\\n### 10'},\n",
       " {'reasoning': 'C√≥ 4 h·ªçc sinh ƒëƒÉng k√Ω h·ªçc nh·∫£y ƒë∆∞∆°ng ƒë·∫°i v√¨ 20/100*20 = 4.\\nC√≥ 16 h·ªçc sinh kh√¥ng ƒëƒÉng k√Ω h·ªçc nh·∫£y ƒë∆∞∆°ng ƒë·∫°i.\\nC√≥ 4 h·ªçc sinh ƒëƒÉng k√Ω h·ªçc nh·∫£y jazz v√¨ 25/100*16 = 4.\\nC√≥ 12 h·ªçc sinh ƒëƒÉng k√Ω h·ªçc nh·∫£y hip-hop v√¨ 16-4 = 12.\\nC√≥ 60% h·ªçc sinh ƒëƒÉng k√Ω h·ªçc nh·∫£y hip-hop v√¨ 12/20 = 0.6.',\n",
       "  'answer': '60',\n",
       "  'raw': 'C√≥ 4 h·ªçc sinh ƒëƒÉng k√Ω h·ªçc nh·∫£y ƒë∆∞∆°ng ƒë·∫°i v√¨ 20/100*20 = 4.\\nC√≥ 16 h·ªçc sinh kh√¥ng ƒëƒÉng k√Ω h·ªçc nh·∫£y ƒë∆∞∆°ng ƒë·∫°i.\\nC√≥ 4 h·ªçc sinh ƒëƒÉng k√Ω h·ªçc nh·∫£y jazz v√¨ 25/100*16 = 4.\\nC√≥ 12 h·ªçc sinh ƒëƒÉng k√Ω h·ªçc nh·∫£y hip-hop v√¨ 16-4 = 12.\\nC√≥ 60% h·ªçc sinh ƒëƒÉng k√Ω h·ªçc nh·∫£y hip-hop v√¨ 12/20 = 0.6.\\n### 60'},\n",
       " {'reasoning': 'N·∫øu nh√† bu√¥n mu·ªën t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n, anh ta n√™n mua trang s·ª©c v·ªõi gi√° $5000.00. K·∫ø ho·∫°ch mua h√†ng th·ª© hai, v·ªõi gi√° $8000.00, kh√¥ng mang l·∫°i l·ª£i nhu·∫≠n v√¨ t·ª∑ l·ªá tƒÉng c·ªßa n√≥ th·∫•p h∆°n so v·ªõi k·∫ø ho·∫°ch ƒë·∫ßu ti√™n. Do ƒë√≥, l·ª£i nhu·∫≠n c·ªßa nh√† bu√¥n s·∫Ω l√† $3000.00 (t√≠nh theo t·ª∑ l·ªá tƒÉng) t·ª´ vi·ªác mua trang s·ª©c.',\n",
       "  'answer': '3000',\n",
       "  'raw': 'N·∫øu nh√† bu√¥n mu·ªën t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n, anh ta n√™n mua trang s·ª©c v·ªõi gi√° $5000.00. K·∫ø ho·∫°ch mua h√†ng th·ª© hai, v·ªõi gi√° $8000.00, kh√¥ng mang l·∫°i l·ª£i nhu·∫≠n v√¨ t·ª∑ l·ªá tƒÉng c·ªßa n√≥ th·∫•p h∆°n so v·ªõi k·∫ø ho·∫°ch ƒë·∫ßu ti√™n. Do ƒë√≥, l·ª£i nhu·∫≠n c·ªßa nh√† bu√¥n s·∫Ω l√† $3000.00 (t√≠nh theo t·ª∑ l·ªá tƒÉng) t·ª´ vi·ªác mua trang s·ª©c.\\n### 3000'},\n",
       " {'reasoning': 'Chuy·∫øn t√†u ƒëi ƒë∆∞·ª£c 80 + 150 = 230 d·∫∑m trong hai ng√†y.\\nV√¨ c√≥ hai chuy·∫øn t√†u, t·ªïng s·ªë d·∫∑m c·ªßa c·∫£ hai l√† 230 * 2 = 460 d·∫∑m.',\n",
       "  'answer': '460',\n",
       "  'raw': 'Chuy·∫øn t√†u ƒëi ƒë∆∞·ª£c 80 + 150 = 230 d·∫∑m trong hai ng√†y.\\nV√¨ c√≥ hai chuy·∫øn t√†u, t·ªïng s·ªë d·∫∑m c·ªßa c·∫£ hai l√† 230 * 2 = 460 d·∫∑m.\\n### 460'},\n",
       " {'reasoning': 'L∆∞∆°ng c·ªßa c√¥ ·∫•y l√† $20/gi·ªù * 35 gi·ªù/tu·∫ßn = $700 m·ªôt tu·∫ßn.\\nV√¨ v·∫≠y, c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c $700/tu·∫ßn * 50 tu·∫ßn/nƒÉm = $35000 m·ªói nƒÉm nh∆∞ m·ªôt gi√°o vi√™n.\\nC√¥ ·∫•y c≈©ng ki·∫øm ƒë∆∞·ª£c $30/gi·ªù * 15 gi·ªù/tu·∫ßn = $450 m·ªôt tu·∫ßn l√†m hu·∫•n luy·ªán vi√™n.\\nƒêi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c $450/tu·∫ßn * 50 tu·∫ßn/nƒÉm = $22500 m·ªói nƒÉm nh∆∞ m·ªôt hu·∫•n luy·ªán vi√™n.\\nDo ƒë√≥, t·ªïng thu nh·∫≠p c·ªßa c√¥ ·∫•y m·ªói nƒÉm l√† $35000 + $22500 = $57500.',\n",
       "  'answer': '57500',\n",
       "  'raw': 'L∆∞∆°ng c·ªßa c√¥ ·∫•y l√† $20/gi·ªù * 35 gi·ªù/tu·∫ßn = $700 m·ªôt tu·∫ßn.\\nV√¨ v·∫≠y, c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c $700/tu·∫ßn * 50 tu·∫ßn/nƒÉm = $35000 m·ªói nƒÉm nh∆∞ m·ªôt gi√°o vi√™n.\\nC√¥ ·∫•y c≈©ng ki·∫øm ƒë∆∞·ª£c $30/gi·ªù * 15 gi·ªù/tu·∫ßn = $450 m·ªôt tu·∫ßn l√†m hu·∫•n luy·ªán vi√™n.\\nƒêi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c $450/tu·∫ßn * 50 tu·∫ßn/nƒÉm = $22500 m·ªói nƒÉm nh∆∞ m·ªôt hu·∫•n luy·ªán vi√™n.\\nDo ƒë√≥, t·ªïng thu nh·∫≠p c·ªßa c√¥ ·∫•y m·ªói nƒÉm l√† $35000 + $22500 = $57500.\\n### 57500'},\n",
       " {'reasoning': '1 tu·∫ßn = 7 ng√†y\\nV√¨ v·∫≠y, 4 tu·∫ßn = 4 * 7 = 28 ng√†y\\nT·ªïng s·ªë tr·ª©ng: 3 tr·ª©ng/ng√†y * 28 ng√†y/tu·∫ßn = 84 tr·ª©ng\\nS·ªë l∆∞·ª£ng tr·ª©ng trong m·ªôt t√° (dozen) l√† 12, v√¨ v·∫≠y 84 tr·ª©ng = 84/12 = 7 t√° tr·ª©ng',\n",
       "  'answer': '7',\n",
       "  'raw': '1 tu·∫ßn = 7 ng√†y\\nV√¨ v·∫≠y, 4 tu·∫ßn = 4 * 7 = 28 ng√†y\\nT·ªïng s·ªë tr·ª©ng: 3 tr·ª©ng/ng√†y * 28 ng√†y/tu·∫ßn = 84 tr·ª©ng\\nS·ªë l∆∞·ª£ng tr·ª©ng trong m·ªôt t√° (dozen) l√† 12, v√¨ v·∫≠y 84 tr·ª©ng = 84/12 = 7 t√° tr·ª©ng\\n### 7'},\n",
       " {'reasoning': 'C√¥ ·∫•y ƒë√£ ƒëi b·ªô ƒë∆∞·ª£c 4+2=6 d·∫∑m trong 1+1=2 gi·ªù.\\nƒêi·ªÅu n√†y c√≥ nghƒ©a l√† c√¥ ·∫•y ph·∫£i ƒëi b·ªô ƒë∆∞·ª£c 12-6=6 d·∫∑m trong 4 gi·ªù.\\nDo ƒë√≥, c√¥ ·∫•y ph·∫£i ƒëi b·ªô v·ªõi v·∫≠n t·ªëc 6/4=1,5 d·∫∑m m·ªói gi·ªù.',\n",
       "  'answer': '1.5',\n",
       "  'raw': 'C√¥ ·∫•y ƒë√£ ƒëi b·ªô ƒë∆∞·ª£c 4+2=6 d·∫∑m trong 1+1=2 gi·ªù.\\nƒêi·ªÅu n√†y c√≥ nghƒ©a l√† c√¥ ·∫•y ph·∫£i ƒëi b·ªô ƒë∆∞·ª£c 12-6=6 d·∫∑m trong 4 gi·ªù.\\nDo ƒë√≥, c√¥ ·∫•y ph·∫£i ƒëi b·ªô v·ªõi v·∫≠n t·ªëc 6/4=1,5 d·∫∑m m·ªói gi·ªù.\\n### 1.5'},\n",
       " {'reasoning': 'M·ªôt l√≠t n∆∞·ªõc hoa qu·∫£ ƒë·∫ßu ti√™n ch·ª©a 10 x 2/3 = 20/3 = 6 2/3 l√≠t n∆∞·ªõc.\\nV√¨ v·∫≠y, m·ªôt l√≠t n∆∞·ªõc hoa qu·∫£ ƒë·∫ßu ti√™n ch·ª©a 10 - 6 2/3 = 3/3 = 1 l√≠t n∆∞·ªõc.\\nM·ªôt l√≠t n∆∞·ªõc hoa qu·∫£ th·ª© hai ch·ª©a 15 x 3/5 = 9 l√≠t n∆∞·ªõc.\\nT·ªïng c·ªông, ch√∫ng ta c√≥ 6 2/3 + 9 = 15 2/3 l√≠t n∆∞·ªõc trong 24 l√≠t.',\n",
       "  'answer': '15',\n",
       "  'raw': 'M·ªôt l√≠t n∆∞·ªõc hoa qu·∫£ ƒë·∫ßu ti√™n ch·ª©a 10 x 2/3 = 20/3 = 6 2/3 l√≠t n∆∞·ªõc.\\nV√¨ v·∫≠y, m·ªôt l√≠t n∆∞·ªõc hoa qu·∫£ ƒë·∫ßu ti√™n ch·ª©a 10 - 6 2/3 = 3/3 = 1 l√≠t n∆∞·ªõc.\\nM·ªôt l√≠t n∆∞·ªõc hoa qu·∫£ th·ª© hai ch·ª©a 15 x 3/5 = 9 l√≠t n∆∞·ªõc.\\nT·ªïng c·ªông, ch√∫ng ta c√≥ 6 2/3 + 9 = 15 2/3 l√≠t n∆∞·ªõc trong 24 l√≠t.\\n### 15'},\n",
       " {'reasoning': 'Samantha ƒëang 31 tu·ªïi, v√¨ v·∫≠y khi c√¥ ·∫•y 23 tu·ªïi, c√¥ ·∫•y ƒë√£ ƒë∆∞·ª£c sinh ra 8 nƒÉm tr∆∞·ªõc ƒë√¢y (t√≠nh t·ª´ h√¥m nay).\\nRaymond ƒë√£ l·ªõn h∆°n Samantha 6 tu·ªïi n√™n khi c√¥ ·∫•y 23 tu·ªïi, anh ta ƒë√£ 29 tu·ªïi (v√¨ 29-6 = 23).\\nƒêi·ªÅu n√†y c√≥ nghƒ©a l√† Raymond ƒë√£ ƒë∆∞·ª£c sinh ra khi anh ta 23 - 6 = 17 tu·ªïi.\\nCon trai c·ªßa Raymond sinh ra khi anh ta 23 tu·ªïi, v√¨ v·∫≠y con trai c·ªßa Raymond ƒë∆∞·ª£c sinh ra 6 nƒÉm tr∆∞·ªõc ƒë√¢y (t√≠nh t·ª´ h√¥m nay).',\n",
       "  'answer': '6',\n",
       "  'raw': 'Samantha ƒëang 31 tu·ªïi, v√¨ v·∫≠y khi c√¥ ·∫•y 23 tu·ªïi, c√¥ ·∫•y ƒë√£ ƒë∆∞·ª£c sinh ra 8 nƒÉm tr∆∞·ªõc ƒë√¢y (t√≠nh t·ª´ h√¥m nay).\\nRaymond ƒë√£ l·ªõn h∆°n Samantha 6 tu·ªïi n√™n khi c√¥ ·∫•y 23 tu·ªïi, anh ta ƒë√£ 29 tu·ªïi (v√¨ 29-6 = 23).\\nƒêi·ªÅu n√†y c√≥ nghƒ©a l√† Raymond ƒë√£ ƒë∆∞·ª£c sinh ra khi anh ta 23 - 6 = 17 tu·ªïi.\\nCon trai c·ªßa Raymond sinh ra khi anh ta 23 tu·ªïi, v√¨ v·∫≠y con trai c·ªßa Raymond ƒë∆∞·ª£c sinh ra 6 nƒÉm tr∆∞·ªõc ƒë√¢y (t√≠nh t·ª´ h√¥m nay).\\n### 6'},\n",
       " {'reasoning': 'Billy ƒë√£ b√°n 1+1+1=3 DVD cho 3 kh√°ch h√†ng ƒë·∫ßu ti√™n.\\nHai kh√°ch h√†ng ti·∫øp theo mua 2 DVD m·ªói ng∆∞·ªùi, t·ªïng c·ªông l√† 2+2=4 DVD.\\nV√¨ v·∫≠y, Billy ƒë√£ b√°n 3+4=7 DVD v√†o th·ª© Ba.',\n",
       "  'answer': '7',\n",
       "  'raw': 'Billy ƒë√£ b√°n 1+1+1=3 DVD cho 3 kh√°ch h√†ng ƒë·∫ßu ti√™n.\\nHai kh√°ch h√†ng ti·∫øp theo mua 2 DVD m·ªói ng∆∞·ªùi, t·ªïng c·ªông l√† 2+2=4 DVD.\\nV√¨ v·∫≠y, Billy ƒë√£ b√°n 3+4=7 DVD v√†o th·ª© Ba.\\n### 7'},\n",
       " {'reasoning': 'ƒê·∫ßu ti√™n t√¨m th·ªùi gian m√† c√¢y n·∫øn b·ªã ch√°y: 5 gi·ªù - 1 gi·ªù = 4 gi·ªù\\nSau ƒë√≥ nh√¢n th·ªùi gian ƒë√≥ v·ªõi t·ªëc ƒë·ªô m·ªói gi·ªù m√† c√¢y n·∫øn b·ªã ch√°y ƒë·ªÉ t√¨m ƒë·ªô d√†i m√† n√≥ b·ªã ch√°y: 4 gi·ªù * 2 centimet/gi·ªù = 8 centimet',\n",
       "  'answer': '8',\n",
       "  'raw': 'ƒê·∫ßu ti√™n t√¨m th·ªùi gian m√† c√¢y n·∫øn b·ªã ch√°y: 5 gi·ªù - 1 gi·ªù = 4 gi·ªù\\nSau ƒë√≥ nh√¢n th·ªùi gian ƒë√≥ v·ªõi t·ªëc ƒë·ªô m·ªói gi·ªù m√† c√¢y n·∫øn b·ªã ch√°y ƒë·ªÉ t√¨m ƒë·ªô d√†i m√† n√≥ b·ªã ch√°y: 4 gi·ªù * 2 centimet/gi·ªù = 8 centimet\\n### 8'},\n",
       " {'reasoning': 'Gi·∫£ s·ª≠ x l√† gi√° c·ªßa cu·ªën s√°ch.\\nV√¨ c√≥ gi·∫£m gi√° 25%, v·∫≠y gi√° gi·∫£m l√† x * 0.25 = 0.25x.\\nV·∫≠y, x - 0.25x = 0.75x = 19.50.\\nDo ƒë√≥, gi√° g·ªëc l√† 0.75x = 19.50.\\nChia c·∫£ hai v·∫ø cho 0.75 ta ƒë∆∞·ª£c x = 19.50 / 0.75 = 26.',\n",
       "  'answer': '26',\n",
       "  'raw': 'Gi·∫£ s·ª≠ x l√† gi√° c·ªßa cu·ªën s√°ch.\\nV√¨ c√≥ gi·∫£m gi√° 25%, v·∫≠y gi√° gi·∫£m l√† x * 0.25 = 0.25x.\\nV·∫≠y, x - 0.25x = 0.75x = 19.50.\\nDo ƒë√≥, gi√° g·ªëc l√† 0.75x = 19.50.\\nChia c·∫£ hai v·∫ø cho 0.75 ta ƒë∆∞·ª£c x = 19.50 / 0.75 = 26.\\n### 26'},\n",
       " {'reasoning': 'Gia c√¥ng c√°c m√≥n g√† s·∫Ω t·ªën 12 ƒë√¥ la.\\nC√°c g√≥i s·ªØa s·∫Ω t·ªën 5 x 3 = 15 ƒë√¥ la.\\nNh·ªØng qu·∫£ t√°o s·∫Ω t·ªën 4 x 1.50 = 6 ƒë√¥ la.\\nT·ªïng chi ph√≠ cho g√†, s·ªØa v√† t√°o l√† 12 + 15 + 6 = 33 ƒë√¥ la.\\nChi ph√≠ cho nh·ªØng chi·∫øc b√°nh pizza l√† 50 - 33 = 17 ƒë√¥ la.\\nV√¨ v·∫≠y, Marie ƒë√£ ƒë·∫∑t 1 h·ªôp pizza v√¨ 17/8.5 = 2.',\n",
       "  'answer': '2',\n",
       "  'raw': 'Gia c√¥ng c√°c m√≥n g√† s·∫Ω t·ªën 12 ƒë√¥ la.\\nC√°c g√≥i s·ªØa s·∫Ω t·ªën 5 x 3 = 15 ƒë√¥ la.\\nNh·ªØng qu·∫£ t√°o s·∫Ω t·ªën 4 x 1.50 = 6 ƒë√¥ la.\\nT·ªïng chi ph√≠ cho g√†, s·ªØa v√† t√°o l√† 12 + 15 + 6 = 33 ƒë√¥ la.\\nChi ph√≠ cho nh·ªØng chi·∫øc b√°nh pizza l√† 50 - 33 = 17 ƒë√¥ la.\\nV√¨ v·∫≠y, Marie ƒë√£ ƒë·∫∑t 1 h·ªôp pizza v√¨ 17/8.5 = 2.\\n### 2'},\n",
       " {'reasoning': 'Gi√° c·ªßa 3 c√°i qu·∫ßn short l√† 16.50 * 3 = 49.50 ƒë√¥ la.\\nGi√° c·ªßa 3 c√°i qu·∫ßn d√†i l√† 22.50 * 3 = 67.50 ƒë√¥ la.\\nV√¨ v·∫≠y, Mishka ƒë√£ chi 49.50 + 67.50 + 42 = 169 ƒë√¥ la cho t·∫•t c·∫£ c√°c m·∫∑t h√†ng qu·∫ßn √°o.',\n",
       "  'answer': '169',\n",
       "  'raw': 'Gi√° c·ªßa 3 c√°i qu·∫ßn short l√† 16.50 * 3 = 49.50 ƒë√¥ la.\\nGi√° c·ªßa 3 c√°i qu·∫ßn d√†i l√† 22.50 * 3 = 67.50 ƒë√¥ la.\\nV√¨ v·∫≠y, Mishka ƒë√£ chi 49.50 + 67.50 + 42 = 169 ƒë√¥ la cho t·∫•t c·∫£ c√°c m·∫∑t h√†ng qu·∫ßn √°o.\\n### 169'},\n",
       " {'reasoning': 'C√¥ ·∫•y ti√™u $4.00 m·ªói th√°ng ƒë·ªÉ mua kem v√† c√¥ ·∫•y ti√™u $2.40 m·ªói ng√†y v√¨ 4/3 = 1.33.\\nV·∫≠y, c√¥ ·∫•y ti√™u $2.40 m·ªói ng√†y v√† c√¥ ·∫•y s·∫Ω ti√™u $240.00 trong 60 ng√†y v√¨ 60 x 4 = 240.',\n",
       "  'answer': '240',\n",
       "  'raw': 'C√¥ ·∫•y ti√™u $4.00 m·ªói th√°ng ƒë·ªÉ mua kem v√† c√¥ ·∫•y ti√™u $2.40 m·ªói ng√†y v√¨ 4/3 = 1.33.\\nV·∫≠y, c√¥ ·∫•y ti√™u $2.40 m·ªói ng√†y v√† c√¥ ·∫•y s·∫Ω ti√™u $240.00 trong 60 ng√†y v√¨ 60 x 4 = 240.\\n### 240'},\n",
       " {'reasoning': 'L·∫ßn d·ª´ng th·ª© hai c·ªßa anh ta ƒë√£ x·∫£y ra ·ªü 45 d·∫∑m (60-15=45).\\nAnh ta ƒë√£ ƒëi ƒë∆∞·ª£c 25 d·∫∑m gi·ªØa l·∫ßn d·ª´ng ƒë·∫ßu ti√™n v√† l·∫ßn d·ª´ng th·ª© hai (45-25=20).',\n",
       "  'answer': '25',\n",
       "  'raw': 'L·∫ßn d·ª´ng th·ª© hai c·ªßa anh ta ƒë√£ x·∫£y ra ·ªü 45 d·∫∑m (60-15=45).\\nAnh ta ƒë√£ ƒëi ƒë∆∞·ª£c 25 d·∫∑m gi·ªØa l·∫ßn d·ª´ng ƒë·∫ßu ti√™n v√† l·∫ßn d·ª´ng th·ª© hai (45-25=20).\\n### 25'},\n",
       " {'reasoning': 'M·ªôt ƒë√¥i gi√†y cao g√≥t kh√°c c√≥ gi√° l√† $33 x 2 = $66.\\nV√¨ v·∫≠y, c·∫£ hai ƒë√¥i gi√†y cao g√≥t c√≥ t·ªïng gi√° l√† $66 + $66 = $132.\\nDo ƒë√≥, ƒë√¥i boots c√≥ gi√° l√† $132 + $5 = $137.',\n",
       "  'answer': '137',\n",
       "  'raw': 'M·ªôt ƒë√¥i gi√†y cao g√≥t kh√°c c√≥ gi√° l√† $33 x 2 = $66.\\nV√¨ v·∫≠y, c·∫£ hai ƒë√¥i gi√†y cao g√≥t c√≥ t·ªïng gi√° l√† $66 + $66 = $132.\\nDo ƒë√≥, ƒë√¥i boots c√≥ gi√° l√† $132 + $5 = $137.\\n### 137'},\n",
       " {'reasoning': 'T·ªïng t·ª∑ l·ªá ƒë·∫°i di·ªán cho tu·ªïi c·ªßa hai ng∆∞·ªùi l√† 7+11 = 18. M·ªôt ph·∫ßn c·ªßa t·ªïng t·ª∑ l·ªá ƒë·∫°i di·ªán cho tu·ªïi c·ªßa Allen l√† 11/18, v√¨ v·∫≠y tu·ªïi c·ªßa Allen l√† (11/18)*162 = 108 tu·ªïi. Trong 10 nƒÉm t·ªõi, tu·ªïi c·ªßa Allen s·∫Ω l√† 108 + 10 = 118.',\n",
       "  'answer': '118',\n",
       "  'raw': 'T·ªïng t·ª∑ l·ªá ƒë·∫°i di·ªán cho tu·ªïi c·ªßa hai ng∆∞·ªùi l√† 7+11 = 18. M·ªôt ph·∫ßn c·ªßa t·ªïng t·ª∑ l·ªá ƒë·∫°i di·ªán cho tu·ªïi c·ªßa Allen l√† 11/18, v√¨ v·∫≠y tu·ªïi c·ªßa Allen l√† (11/18)*162 = 108 tu·ªïi. Trong 10 nƒÉm t·ªõi, tu·ªïi c·ªßa Allen s·∫Ω l√† 108 + 10 = 118.\\n### 118'},\n",
       " {'reasoning': 'Ng∆∞·ªùi ƒë·∫ßu ti√™n ƒëo√°n 80 vi√™n k·∫πo.\\nM·ªôt n·ª≠a s·ªë k·∫πo l√† 80/2 = 40 vi√™n k·∫πo.\\nV·∫≠y, ng∆∞·ªùi th·ª© hai ƒëo√°n l√† 40 + 20 = 60 vi√™n k·∫πo.\\nT·ªïng s·ªë k·∫πo ƒëo√°n c·ªßa h·ªç l√† 80 + 60 + 40 = 180 vi√™n k·∫πo.\\nS·ªë k·∫πo ƒëo√°n trung b√¨nh l√† 180/3 = 60 vi√™n k·∫πo.',\n",
       "  'answer': '60',\n",
       "  'raw': 'Ng∆∞·ªùi ƒë·∫ßu ti√™n ƒëo√°n 80 vi√™n k·∫πo.\\nM·ªôt n·ª≠a s·ªë k·∫πo l√† 80/2 = 40 vi√™n k·∫πo.\\nV·∫≠y, ng∆∞·ªùi th·ª© hai ƒëo√°n l√† 40 + 20 = 60 vi√™n k·∫πo.\\nT·ªïng s·ªë k·∫πo ƒëo√°n c·ªßa h·ªç l√† 80 + 60 + 40 = 180 vi√™n k·∫πo.\\nS·ªë k·∫πo ƒëo√°n trung b√¨nh l√† 180/3 = 60 vi√™n k·∫πo.\\n### 60'},\n",
       " {'reasoning': 'Anh ta c√≥ 10 con ch√≥ v√† m·ªói con ch√≥ m·∫•t 0,5 gi·ªù m·ªói ng√†y ƒë·ªÉ ƒëi d·∫°o n√™n anh ta d√†nh 5 gi·ªù m·ªói ng√†y cho c√°c con ch√≥. Anh ta d√†nh 5 gi·ªù m·ªói ng√†y cho ch√≥ v√† anh ta ƒëi d·∫°o v·ªõi ch√∫ng trong 7 ng√†y n√™n anh ta d√†nh 35 gi·ªù m·ªói tu·∫ßn.',\n",
       "  'answer': '35',\n",
       "  'raw': 'Anh ta c√≥ 10 con ch√≥ v√† m·ªói con ch√≥ m·∫•t 0,5 gi·ªù m·ªói ng√†y ƒë·ªÉ ƒëi d·∫°o n√™n anh ta d√†nh 5 gi·ªù m·ªói ng√†y cho c√°c con ch√≥. Anh ta d√†nh 5 gi·ªù m·ªói ng√†y cho ch√≥ v√† anh ta ƒëi d·∫°o v·ªõi ch√∫ng trong 7 ng√†y n√™n anh ta d√†nh 35 gi·ªù m·ªói tu·∫ßn.\\n### 35'},\n",
       " {'reasoning': 'V√¨ c√≥ 30 ƒë·ªìng xu v√†ng nhi·ªÅu h∆°n ƒë·ªìng xu b·∫°c, n√™n s·ªë ƒë·ªìng xu v√†ng b·∫±ng v·ªõi s·ªë ƒë·ªìng xu b·∫°c l√† 110/2 = 55 ƒë·ªìng xu.\\nDo ƒë√≥, s·ªë ƒë·ªìng xu v√†ng l√† 55 + 30 = 85 ƒë·ªìng xu.',\n",
       "  'answer': '85',\n",
       "  'raw': 'V√¨ c√≥ 30 ƒë·ªìng xu v√†ng nhi·ªÅu h∆°n ƒë·ªìng xu b·∫°c, n√™n s·ªë ƒë·ªìng xu v√†ng b·∫±ng v·ªõi s·ªë ƒë·ªìng xu b·∫°c l√† 110/2 = 55 ƒë·ªìng xu.\\nDo ƒë√≥, s·ªë ƒë·ªìng xu v√†ng l√† 55 + 30 = 85 ƒë·ªìng xu.\\n### 85'},\n",
       " {'reasoning': 'M·ªôt n·ª≠a s·ªë vi√™n ƒë√° qu√Ω c·ªßa Raymond l√† 40/2 = 20 vi√™n.\\nAaron c√≥ 20+5 = 25 vi√™n ƒë√° qu√Ω.\\nV·∫≠y, Siobhan c√≥ 25-2 = 23 vi√™n ƒë√° qu√Ω.',\n",
       "  'answer': '23',\n",
       "  'raw': 'M·ªôt n·ª≠a s·ªë vi√™n ƒë√° qu√Ω c·ªßa Raymond l√† 40/2 = 20 vi√™n.\\nAaron c√≥ 20+5 = 25 vi√™n ƒë√° qu√Ω.\\nV·∫≠y, Siobhan c√≥ 25-2 = 23 vi√™n ƒë√° qu√Ω.\\n### 23'},\n",
       " {'reasoning': 'Anh ta ghi ƒë∆∞·ª£c 4 ƒëi·ªÉm trong kho·∫£ng th·ªùi gian ƒë·∫ßu ti√™n, v√† 25% nhi·ªÅu h∆°n, v√¨ v·∫≠y anh ta ghi ƒë∆∞·ª£c 1 ƒëi·ªÉm nhi·ªÅu h∆°n. T·ªïng s·ªë ƒëi·ªÉm c·ªßa anh ta trong kho·∫£ng th·ªùi gian th·ª© hai l√† 5. Anh ta ghi ƒë∆∞·ª£c 4 ƒëi·ªÉm trong kho·∫£ng th·ªùi gian ƒë·∫ßu ti√™n v√† 5 ƒëi·ªÉm trong kho·∫£ng th·ªùi gian th·ª© hai, t·ªïng c·ªông l√† 9 ƒëi·ªÉm.',\n",
       "  'answer': '9',\n",
       "  'raw': 'Anh ta ghi ƒë∆∞·ª£c 4 ƒëi·ªÉm trong kho·∫£ng th·ªùi gian ƒë·∫ßu ti√™n, v√† 25% nhi·ªÅu h∆°n, v√¨ v·∫≠y anh ta ghi ƒë∆∞·ª£c 1 ƒëi·ªÉm nhi·ªÅu h∆°n. T·ªïng s·ªë ƒëi·ªÉm c·ªßa anh ta trong kho·∫£ng th·ªùi gian th·ª© hai l√† 5. Anh ta ghi ƒë∆∞·ª£c 4 ƒëi·ªÉm trong kho·∫£ng th·ªùi gian ƒë·∫ßu ti√™n v√† 5 ƒëi·ªÉm trong kho·∫£ng th·ªùi gian th·ª© hai, t·ªïng c·ªông l√† 9 ƒëi·ªÉm.\\n### 9'},\n",
       " {'reasoning': 'Anh ta ƒÉn 2 h·ªôp s·ªØa chua m·ªói ng√†y, v√¨ v·∫≠y trong 30 ng√†y anh ta ƒÉn ƒë∆∞·ª£c 2*30 = 60 h·ªôp s·ªØa chua. M·ª©c gi√° ƒë∆∞·ª£c gi·∫£m cho 4 h·ªôp s·ªØa chua l√† $5.00 v√† anh ta c·∫ßn 60 h·ªôp s·ªØa chua, v√¨ v·∫≠y anh ta c·∫ßn 60/4 = 15 b·ªô. M·ªói b·ªô c√≥ gi√° $5.00 v√† anh ta c·∫ßn 15 b·ªô, v√¨ v·∫≠y t·ªïng chi ph√≠ cho 30 ng√†y l√† 5*15 = $75.00.',\n",
       "  'answer': '75',\n",
       "  'raw': 'Anh ta ƒÉn 2 h·ªôp s·ªØa chua m·ªói ng√†y, v√¨ v·∫≠y trong 30 ng√†y anh ta ƒÉn ƒë∆∞·ª£c 2*30 = 60 h·ªôp s·ªØa chua. M·ª©c gi√° ƒë∆∞·ª£c gi·∫£m cho 4 h·ªôp s·ªØa chua l√† $5.00 v√† anh ta c·∫ßn 60 h·ªôp s·ªØa chua, v√¨ v·∫≠y anh ta c·∫ßn 60/4 = 15 b·ªô. M·ªói b·ªô c√≥ gi√° $5.00 v√† anh ta c·∫ßn 15 b·ªô, v√¨ v·∫≠y t·ªïng chi ph√≠ cho 30 ng√†y l√† 5*15 = $75.00.\\n### 75'},\n",
       " {'reasoning': 'Anh ta ki·∫øm ƒë∆∞·ª£c $15 x 13 = $195 t·ª´ vi·ªác b√°n c√°c kh·ªëi Lego. V√¨ v·∫≠y, anh ta ƒë√£ chi $195 - $5 = $190 cho c√°c tr√≤ ch∆°i ƒëi·ªán t·ª≠. Do ƒë√≥, anh ta ƒë√£ chi $190 / $20 = 9,5 = 9 b·ªô tr√≤ ch∆°i ƒëi·ªán t·ª≠ (t√≠nh b·∫±ng s·ªë l∆∞·ª£ng, kh√¥ng ph·∫£i s·ªë ti·ªÅn). V√¨ v·∫≠y, anh ta v·∫´n c√≤n l·∫°i 4 b·ªô Lego.',\n",
       "  'answer': '4',\n",
       "  'raw': 'Anh ta ki·∫øm ƒë∆∞·ª£c $15 x 13 = $195 t·ª´ vi·ªác b√°n c√°c kh·ªëi Lego. V√¨ v·∫≠y, anh ta ƒë√£ chi $195 - $5 = $190 cho c√°c tr√≤ ch∆°i ƒëi·ªán t·ª≠. Do ƒë√≥, anh ta ƒë√£ chi $190 / $20 = 9,5 = 9 b·ªô tr√≤ ch∆°i ƒëi·ªán t·ª≠ (t√≠nh b·∫±ng s·ªë l∆∞·ª£ng, kh√¥ng ph·∫£i s·ªë ti·ªÅn). V√¨ v·∫≠y, anh ta v·∫´n c√≤n l·∫°i 4 b·ªô Lego.\\n### 4'},\n",
       " {'reasoning': 'Anh ta ch·∫°y 3 gi·ªù v√†o ng√†y ƒë·∫ßu ti√™n, v√¨ v·∫≠y anh ta ch·∫°y 1.5 gi·ªù v√†o hai ng√†y c√≤n l·∫°i.\\nV·∫≠y anh ta ch·∫°y t·ªïng c·ªông 3 + 1.5 + 1.5 = 6 gi·ªù trong tu·∫ßn.\\nƒêi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† anh ta ch·∫°y 60/6 = 10 d·∫∑m m·ªói gi·ªù.',\n",
       "  'answer': '10',\n",
       "  'raw': 'Anh ta ch·∫°y 3 gi·ªù v√†o ng√†y ƒë·∫ßu ti√™n, v√¨ v·∫≠y anh ta ch·∫°y 1.5 gi·ªù v√†o hai ng√†y c√≤n l·∫°i.\\nV·∫≠y anh ta ch·∫°y t·ªïng c·ªông 3 + 1.5 + 1.5 = 6 gi·ªù trong tu·∫ßn.\\nƒêi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† anh ta ch·∫°y 60/6 = 10 d·∫∑m m·ªói gi·ªù.\\n### 10'},\n",
       " {'reasoning': 'S·ªë d·∫∑m m√† Dana c√≥ th·ªÉ ƒëi trong m·ªôt gi·ªù l√† 6/2 = 3 d·∫∑m.\\nT·ªëc ƒë·ªô ch·∫°y c·ªßa Dana l√† 3*2 = 6 d·∫∑m m·ªôt gi·ªù.\\nT·ªëc ƒë·ªô ƒëi b·ªô c·ªßa Dana l√† 6/4 = 1.5 d·∫∑m m·ªôt gi·ªù.\\nN·∫øu Dana d√†nh m·ªôt ph·∫ßn ba th·ªùi gian ch·∫°y, th√¨ c√¥ ·∫•y s·∫Ω ch·∫°y ƒë∆∞·ª£c 1/3*6 = 2 d·∫∑m.\\nN·∫øu Dana d√†nh hai ph·∫ßn ba th·ªùi gian ƒëi b·ªô, th√¨ c√¥ ·∫•y s·∫Ω ƒëi b·ªô ƒë∆∞·ª£c 2/3*6 = 4 d·∫∑m.\\nV√¨ v·∫≠y, Dana c√≥ th·ªÉ ƒëi ƒë∆∞·ª£c 2+4 = 6 d·∫∑m.',\n",
       "  'answer': '6',\n",
       "  'raw': 'S·ªë d·∫∑m m√† Dana c√≥ th·ªÉ ƒëi trong m·ªôt gi·ªù l√† 6/2 = 3 d·∫∑m.\\nT·ªëc ƒë·ªô ch·∫°y c·ªßa Dana l√† 3*2 = 6 d·∫∑m m·ªôt gi·ªù.\\nT·ªëc ƒë·ªô ƒëi b·ªô c·ªßa Dana l√† 6/4 = 1.5 d·∫∑m m·ªôt gi·ªù.\\nN·∫øu Dana d√†nh m·ªôt ph·∫ßn ba th·ªùi gian ch·∫°y, th√¨ c√¥ ·∫•y s·∫Ω ch·∫°y ƒë∆∞·ª£c 1/3*6 = 2 d·∫∑m.\\nN·∫øu Dana d√†nh hai ph·∫ßn ba th·ªùi gian ƒëi b·ªô, th√¨ c√¥ ·∫•y s·∫Ω ƒëi b·ªô ƒë∆∞·ª£c 2/3*6 = 4 d·∫∑m.\\nV√¨ v·∫≠y, Dana c√≥ th·ªÉ ƒëi ƒë∆∞·ª£c 2+4 = 6 d·∫∑m.\\n### 6'},\n",
       " {'reasoning': 'ƒêi·ªán tho·∫°i iPhone c·ªßa Ben ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong 2 nƒÉm (1*2).\\nƒêi·ªán tho·∫°i iPhone c·ªßa Brandon ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong 8 nƒÉm (2*4).',\n",
       "  'answer': '8',\n",
       "  'raw': 'ƒêi·ªán tho·∫°i iPhone c·ªßa Ben ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong 2 nƒÉm (1*2).\\nƒêi·ªán tho·∫°i iPhone c·ªßa Brandon ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong 8 nƒÉm (2*4).\\n### 8'},\n",
       " {'reasoning': 'N·∫øu gi√°o v√†ng c√≥ th·ªÉ ƒë·∫°t t·ªõi t·∫ßm c·ªßa ng·ªçn l·ª≠a c·ªßa con r·ªìng, th√¨ gi√°o s·∫Ω c·∫ßn ph·∫£i c√≥ th·ªÉ n√©m ƒë∆∞·ª£c xa h∆°n g·∫•p ba l·∫ßn, t·ª©c l√† 3*400=1200 feet. N·∫øu gi√°o c√≥ th·ªÉ n√©m ƒë∆∞·ª£c xa g·∫•p ba l·∫ßn khi c√≥ vi√™n ng·ªçc, th√¨ gi√°o s·∫Ω c·∫ßn ph·∫£i c√≥ th·ªÉ n√©m ƒë∆∞·ª£c xa g·∫•p ba l·∫ßn, t·ª©c l√† 3*1200=3600 feet.',\n",
       "  'answer': '3600',\n",
       "  'raw': 'N·∫øu gi√°o v√†ng c√≥ th·ªÉ ƒë·∫°t t·ªõi t·∫ßm c·ªßa ng·ªçn l·ª≠a c·ªßa con r·ªìng, th√¨ gi√°o s·∫Ω c·∫ßn ph·∫£i c√≥ th·ªÉ n√©m ƒë∆∞·ª£c xa h∆°n g·∫•p ba l·∫ßn, t·ª©c l√† 3*400=1200 feet. N·∫øu gi√°o c√≥ th·ªÉ n√©m ƒë∆∞·ª£c xa g·∫•p ba l·∫ßn khi c√≥ vi√™n ng·ªçc, th√¨ gi√°o s·∫Ω c·∫ßn ph·∫£i c√≥ th·ªÉ n√©m ƒë∆∞·ª£c xa g·∫•p ba l·∫ßn, t·ª©c l√† 3*1200=3600 feet.\\n### 3600'},\n",
       " {'reasoning': 'C√≥ t·ªïng c·ªông 40 mi·∫øng b√°nh (t√≠nh tr√™n s·ªë b√°nh v√† mi·∫øng b√°nh). Kh√°ch ƒë√£ l·∫•y 26 mi·∫øng b√°nh.',\n",
       "  'answer': '26',\n",
       "  'raw': 'C√≥ t·ªïng c·ªông 40 mi·∫øng b√°nh (t√≠nh tr√™n s·ªë b√°nh v√† mi·∫øng b√°nh). Kh√°ch ƒë√£ l·∫•y 26 mi·∫øng b√°nh.\\n### 26'},\n",
       " {'reasoning': 'N·∫øu m·ªôt kh·∫©u ph·∫ßn c√≥ 250 calo v√† m·ªôt t√∫i c√≥ 5 kh·∫©u ph·∫ßn, th√¨ 5*250=1250 calo trong m·ªôt t√∫i. B·∫°n ƒë√£ ti√™u th·ª• 1800 calo v√† m·ª•c ti√™u c·ªßa b·∫°n l√† 2000 calo, v√¨ v·∫≠y b·∫°n c√≤n d∆∞ 2000-1800=200 calo. M·ªôt kh·∫©u ph·∫ßn c√≥ 250 calo v√† b·∫°n c·∫ßn 200 calo, v√¨ v·∫≠y b·∫°n c√≥ th·ªÉ ƒÉn th√™m 200/250=0.8 kh·∫©u ph·∫ßn. M·ªôt t√∫i c√≥ 5 kh·∫©u ph·∫ßn v√† b·∫°n c√≥ th·ªÉ ƒÉn th√™m 0.8 kh·∫©u ph·∫ßn, v√¨ v·∫≠y b·∫°n c√≥ th·ªÉ ƒÉn th√™m 5*.8=4 kh·∫©u ph·∫ßn. M·ª©c ti√™u th·ª• calo c·ªßa b·∫°n l√† 250 calo tr√™n m·ªói kh·∫©u ph·∫ßn v√† b·∫°n c√≥ th·ªÉ ƒÉn th√™m 4 kh·∫©u ph·∫ßn n·ªØa, v√¨ v·∫≠y t·ªïng s·ªë calo b·∫°n c√≥ th·ªÉ ti√™u th·ª• th√™m l√† 250*4=1000 calo.',\n",
       "  'answer': '1000',\n",
       "  'raw': 'N·∫øu m·ªôt kh·∫©u ph·∫ßn c√≥ 250 calo v√† m·ªôt t√∫i c√≥ 5 kh·∫©u ph·∫ßn, th√¨ 5*250=1250 calo trong m·ªôt t√∫i. B·∫°n ƒë√£ ti√™u th·ª• 1800 calo v√† m·ª•c ti√™u c·ªßa b·∫°n l√† 2000 calo, v√¨ v·∫≠y b·∫°n c√≤n d∆∞ 2000-1800=200 calo. M·ªôt kh·∫©u ph·∫ßn c√≥ 250 calo v√† b·∫°n c·∫ßn 200 calo, v√¨ v·∫≠y b·∫°n c√≥ th·ªÉ ƒÉn th√™m 200/250=0.8 kh·∫©u ph·∫ßn. M·ªôt t√∫i c√≥ 5 kh·∫©u ph·∫ßn v√† b·∫°n c√≥ th·ªÉ ƒÉn th√™m 0.8 kh·∫©u ph·∫ßn, v√¨ v·∫≠y b·∫°n c√≥ th·ªÉ ƒÉn th√™m 5*.8=4 kh·∫©u ph·∫ßn. M·ª©c ti√™u th·ª• calo c·ªßa b·∫°n l√† 250 calo tr√™n m·ªói kh·∫©u ph·∫ßn v√† b·∫°n c√≥ th·ªÉ ƒÉn th√™m 4 kh·∫©u ph·∫ßn n·ªØa, v√¨ v·∫≠y t·ªïng s·ªë calo b·∫°n c√≥ th·ªÉ ti√™u th·ª• th√™m l√† 250*4=1000 calo.\\n### 1000'},\n",
       " {'reasoning': 'Anh ta l√†m ƒë∆∞·ª£c 200 c√¢y n·∫øn v·ªõi 20 x 10 = 200 c√¢y n·∫øn.\\nV·ªõi 1 pound s√°p ong, anh ta l√†m ƒë∆∞·ª£c 200/10 = 20 pound s√°p ong.\\nV·ªõi 20 pound s√°p ong, anh ta c·∫ßn 20 x 10 = 200 d√¢y chuy·ªÅn.\\nV·ªõi 200 d√¢y chuy·ªÅn, anh ta c·∫ßn 200 x 10 = 2000 pound s√°p ong.\\nM·ªôt pound s√°p ong v√† d√¢y chuy·ªÅn c√≥ gi√° $10, v√¨ v·∫≠y anh ta chi ti√™u 2000 x 10 = $20,000.\\nM·ªói c√¢y n·∫øn c√≥ gi√° $2.00 v√† anh ta ƒë√£ b√°n ƒë∆∞·ª£c 20 c√¢y, v√¨ v·∫≠y t·ªïng thu nh·∫≠p c·ªßa anh ta l√† 20 x 2 = $40.00.\\nL·ª£i nhu·∫≠n c·ªßa anh ta l√† 40 - 2000 = -$1960.00.',\n",
       "  'answer': '-1960',\n",
       "  'raw': 'Anh ta l√†m ƒë∆∞·ª£c 200 c√¢y n·∫øn v·ªõi 20 x 10 = 200 c√¢y n·∫øn.\\nV·ªõi 1 pound s√°p ong, anh ta l√†m ƒë∆∞·ª£c 200/10 = 20 pound s√°p ong.\\nV·ªõi 20 pound s√°p ong, anh ta c·∫ßn 20 x 10 = 200 d√¢y chuy·ªÅn.\\nV·ªõi 200 d√¢y chuy·ªÅn, anh ta c·∫ßn 200 x 10 = 2000 pound s√°p ong.\\nM·ªôt pound s√°p ong v√† d√¢y chuy·ªÅn c√≥ gi√° $10, v√¨ v·∫≠y anh ta chi ti√™u 2000 x 10 = $20,000.\\nM·ªói c√¢y n·∫øn c√≥ gi√° $2.00 v√† anh ta ƒë√£ b√°n ƒë∆∞·ª£c 20 c√¢y, v√¨ v·∫≠y t·ªïng thu nh·∫≠p c·ªßa anh ta l√† 20 x 2 = $40.00.\\nL·ª£i nhu·∫≠n c·ªßa anh ta l√† 40 - 2000 = -$1960.00.\\n### -1960'},\n",
       " {'reasoning': 'V√¨ c√¥ ·∫•y vi·∫øt 5 b√†i vi·∫øt v√†o Th·ª© Hai, c√¥ ·∫•y ƒë√£ d√†nh 5 * 4 = 20 gi·ªù ƒë·ªÉ vi·∫øt nh·ªØng b√†i vi·∫øt ƒë√≥.\\nTh·ª© Ba, c√¥ ·∫•y ƒë√£ vi·∫øt nhi·ªÅu h∆°n 2/5 s·ªë b√†i vi·∫øt so v·ªõi Th·ª© Hai, t·ª©c l√† 2/5 * 5 = 2 b√†i vi·∫øt.\\nDo ƒë√≥, c√¥ ·∫•y ƒë√£ vi·∫øt 7 b√†i vi·∫øt v√†o Th·ª© Ba (5 + 2).\\nC√¥ ·∫•y ƒë√£ d√†nh 7 * 4 = 28 gi·ªù ƒë·ªÉ vi·∫øt nh·ªØng b√†i vi·∫øt ƒë√≥.\\nTh·ª© T∆∞, c√¥ ·∫•y ƒë√£ vi·∫øt g·∫•p ƒë√¥i s·ªë b√†i vi·∫øt so v·ªõi Th·ª© Ba, t·ª©c l√† 2 * 7 = 14 b√†i vi·∫øt.\\nV√¨ v·∫≠y, c√¥ ·∫•y ƒë√£ d√†nh 14 * 4 = 56 gi·ªù ƒë·ªÉ vi·∫øt nh·ªØng b√†i vi·∫øt ƒë√≥.\\nV√¨ v·∫≠y, t·ªïng s·ªë gi·ªù c√¥ ·∫•y ƒë√£ d√†nh cho vi·ªác vi·∫øt b√†i trong ba ng√†y l√† 20 + 28 + 56 = 104 gi·ªù.',\n",
       "  'answer': '104',\n",
       "  'raw': 'V√¨ c√¥ ·∫•y vi·∫øt 5 b√†i vi·∫øt v√†o Th·ª© Hai, c√¥ ·∫•y ƒë√£ d√†nh 5 * 4 = 20 gi·ªù ƒë·ªÉ vi·∫øt nh·ªØng b√†i vi·∫øt ƒë√≥.\\nTh·ª© Ba, c√¥ ·∫•y ƒë√£ vi·∫øt nhi·ªÅu h∆°n 2/5 s·ªë b√†i vi·∫øt so v·ªõi Th·ª© Hai, t·ª©c l√† 2/5 * 5 = 2 b√†i vi·∫øt.\\nDo ƒë√≥, c√¥ ·∫•y ƒë√£ vi·∫øt 7 b√†i vi·∫øt v√†o Th·ª© Ba (5 + 2).\\nC√¥ ·∫•y ƒë√£ d√†nh 7 * 4 = 28 gi·ªù ƒë·ªÉ vi·∫øt nh·ªØng b√†i vi·∫øt ƒë√≥.\\nTh·ª© T∆∞, c√¥ ·∫•y ƒë√£ vi·∫øt g·∫•p ƒë√¥i s·ªë b√†i vi·∫øt so v·ªõi Th·ª© Ba, t·ª©c l√† 2 * 7 = 14 b√†i vi·∫øt.\\nV√¨ v·∫≠y, c√¥ ·∫•y ƒë√£ d√†nh 14 * 4 = 56 gi·ªù ƒë·ªÉ vi·∫øt nh·ªØng b√†i vi·∫øt ƒë√≥.\\nV√¨ v·∫≠y, t·ªïng s·ªë gi·ªù c√¥ ·∫•y ƒë√£ d√†nh cho vi·ªác vi·∫øt b√†i trong ba ng√†y l√† 20 + 28 + 56 = 104 gi·ªù.\\n### 104'},\n",
       " {'reasoning': 'T·ªïng s·ªë t·ªù d√°n Post-it m√† Candice c√≥ sau khi gh√© qua c·ª≠a h√†ng l√† 80 + 23 = 103 t·ªù d√°n Post-it.\\nS·ªë t·ªù d√°n Post-it m√† Candice ƒë√£ s·ª≠ d·ª•ng ƒë·ªÉ d√°n l√™n c·ªëc c√† ph√™ l√† 220 - 103 = 117 t·ªù d√°n Post-it.\\nDo ƒë√≥, Candice ƒë√£ mua 117 t·ªù d√°n Post-it trong g√≥i.',\n",
       "  'answer': '117',\n",
       "  'raw': 'T·ªïng s·ªë t·ªù d√°n Post-it m√† Candice c√≥ sau khi gh√© qua c·ª≠a h√†ng l√† 80 + 23 = 103 t·ªù d√°n Post-it.\\nS·ªë t·ªù d√°n Post-it m√† Candice ƒë√£ s·ª≠ d·ª•ng ƒë·ªÉ d√°n l√™n c·ªëc c√† ph√™ l√† 220 - 103 = 117 t·ªù d√°n Post-it.\\nDo ƒë√≥, Candice ƒë√£ mua 117 t·ªù d√°n Post-it trong g√≥i.\\n### 117'},\n",
       " {'reasoning': 'Anh ta ƒë√£ mua 200/40=5 c√°i c√† v·∫°t m√†u xanh.\\nV·∫≠y anh ta ƒë√£ mua 10 c√°i c√† v·∫°t m√†u ƒë·ªè.\\nC√† v·∫°t m√†u ƒë·ªè t·ªën 40*.5=$20 m·ªói c√°i.\\nV·∫≠y t·ªïng chi ph√≠ cho c√† v·∫°t m√†u ƒë·ªè l√† 10*20=$200.\\nDo ƒë√≥, t·ªïng chi ph√≠ cho c√† v·∫°t l√† 200+200=$400.',\n",
       "  'answer': '400',\n",
       "  'raw': 'Anh ta ƒë√£ mua 200/40=5 c√°i c√† v·∫°t m√†u xanh.\\nV·∫≠y anh ta ƒë√£ mua 10 c√°i c√† v·∫°t m√†u ƒë·ªè.\\nC√† v·∫°t m√†u ƒë·ªè t·ªën 40*.5=$20 m·ªói c√°i.\\nV·∫≠y t·ªïng chi ph√≠ cho c√† v·∫°t m√†u ƒë·ªè l√† 10*20=$200.\\nDo ƒë√≥, t·ªïng chi ph√≠ cho c√† v·∫°t l√† 200+200=$400.\\n### 400'},\n",
       " {'reasoning': 'M·ªôt feet b·∫±ng 12 inch, v√¨ v·∫≠y 4 feet b·∫±ng 4*12=48 inches.\\nV√¨ m·ªói m·∫£nh d√¢y d√†i 6 inch, n√™n c√¥ ·∫•y s·∫Ω c√≥ 48/6 = 8 m·∫£nh d√¢y.',\n",
       "  'answer': '8',\n",
       "  'raw': 'M·ªôt feet b·∫±ng 12 inch, v√¨ v·∫≠y 4 feet b·∫±ng 4*12=48 inches.\\nV√¨ m·ªói m·∫£nh d√¢y d√†i 6 inch, n√™n c√¥ ·∫•y s·∫Ω c√≥ 48/6 = 8 m·∫£nh d√¢y.\\n### 8'},\n",
       " {'reasoning': 'T·ªïng s·ªë cƒÉn h·ªô trong t√≤a nh√† l√† 15 t·∫ßng * 8 cƒÉn h·ªô/t·∫ßng = 120 cƒÉn h·ªô.\\nS·ªë cƒÉn h·ªô ƒë√£ ƒë∆∞·ª£c thu√™ l√† 120 cƒÉn h·ªô * 3/4 = 90 cƒÉn h·ªô.\\nV·∫≠y, s·ªë cƒÉn h·ªô ch∆∞a ƒë∆∞·ª£c thu√™ l√† 120 cƒÉn h·ªô - 90 cƒÉn h·ªô = 30 cƒÉn h·ªô.',\n",
       "  'answer': '30',\n",
       "  'raw': 'T·ªïng s·ªë cƒÉn h·ªô trong t√≤a nh√† l√† 15 t·∫ßng * 8 cƒÉn h·ªô/t·∫ßng = 120 cƒÉn h·ªô.\\nS·ªë cƒÉn h·ªô ƒë√£ ƒë∆∞·ª£c thu√™ l√† 120 cƒÉn h·ªô * 3/4 = 90 cƒÉn h·ªô.\\nV·∫≠y, s·ªë cƒÉn h·ªô ch∆∞a ƒë∆∞·ª£c thu√™ l√† 120 cƒÉn h·ªô - 90 cƒÉn h·ªô = 30 cƒÉn h·ªô.\\n### 30'},\n",
       " {'reasoning': 'M·ªói ng√†y, anh ta ki·∫øm ƒë∆∞·ª£c 252/12 = $21. M·ªói tu·∫ßn, anh ta ki·∫øm ƒë∆∞·ª£c 7 * $21 = $147.',\n",
       "  'answer': '147',\n",
       "  'raw': 'M·ªói ng√†y, anh ta ki·∫øm ƒë∆∞·ª£c 252/12 = $21. M·ªói tu·∫ßn, anh ta ki·∫øm ƒë∆∞·ª£c 7 * $21 = $147.\\n### 147'},\n",
       " {'reasoning': 'Anh ta ƒë√£ ƒëi ƒë∆∞·ª£c 10 d·∫∑m trong 1 gi·ªù, v√¨ v·∫≠y anh ta s·∫Ω m·∫•t 1 gi·ªù ƒë·ªÉ ƒëi l·∫°i.',\n",
       "  'answer': '2',\n",
       "  'raw': 'Anh ta ƒë√£ ƒëi ƒë∆∞·ª£c 10 d·∫∑m trong 1 gi·ªù, v√¨ v·∫≠y anh ta s·∫Ω m·∫•t 1 gi·ªù ƒë·ªÉ ƒëi l·∫°i.\\n### 2'},\n",
       " {'reasoning': 'ƒê·∫ßu ti√™n t√¨m t·ªïng tr·ªçng l∆∞·ª£ng c·ªßa c√°c cu·ªën ti·ªÉu thuy·∫øt: 30 cu·ªën * 1/4 pound/cu·ªën = 7,5 pound\\nSau ƒë√≥ tr·ª´ ƒëi tr·ªçng l∆∞·ª£ng n√†y t·ª´ t·ªïng tr·ªçng l∆∞·ª£ng c·ªßa t√∫i s√°ch ƒë·ªÉ t√¨m ra tr·ªçng l∆∞·ª£ng c·ªßa ƒë·ªì ch∆°i: 15 pound - 7,5 pound = 7,5 pound\\nTi·∫øp theo chia tr·ªçng l∆∞·ª£ng n√†y cho tr·ªçng l∆∞·ª£ng c·ªßa m·ªói ƒë·ªì ch∆°i ƒë·ªÉ t√¨m s·ªë ƒë·ªì ch∆°i: 7,5 pound / 1/2 pound/ƒë·ªì ch∆°i = 15 ƒë·ªì ch∆°i',\n",
       "  'answer': '15',\n",
       "  'raw': 'ƒê·∫ßu ti√™n t√¨m t·ªïng tr·ªçng l∆∞·ª£ng c·ªßa c√°c cu·ªën ti·ªÉu thuy·∫øt: 30 cu·ªën * 1/4 pound/cu·ªën = 7,5 pound\\nSau ƒë√≥ tr·ª´ ƒëi tr·ªçng l∆∞·ª£ng n√†y t·ª´ t·ªïng tr·ªçng l∆∞·ª£ng c·ªßa t√∫i s√°ch ƒë·ªÉ t√¨m ra tr·ªçng l∆∞·ª£ng c·ªßa ƒë·ªì ch∆°i: 15 pound - 7,5 pound = 7,5 pound\\nTi·∫øp theo chia tr·ªçng l∆∞·ª£ng n√†y cho tr·ªçng l∆∞·ª£ng c·ªßa m·ªói ƒë·ªì ch∆°i ƒë·ªÉ t√¨m s·ªë ƒë·ªì ch∆°i: 7,5 pound / 1/2 pound/ƒë·ªì ch∆°i = 15 ƒë·ªì ch∆°i\\n### 15'},\n",
       " {'reasoning': 'V√†o ng√†y th·ª© NƒÉm, th·ª£ m√°y t√≠nh ƒë∆∞·ª£c $60 x 6 = $360 cho vi·ªác s·ª≠a ch·ªØa c√°c l·ªëp xe t·∫£i.\\nV√†o ng√†y th·ª© NƒÉm, th·ª£ m√°y t√≠nh ƒë∆∞·ª£c $40 x 4 = $160 cho vi·ªác s·ª≠a ch·ªØa c√°c l·ªëp xe h∆°i.\\nT·ªïng c·ªông v√†o ng√†y th·ª© NƒÉm, th·ª£ m√°y ki·∫øm ƒë∆∞·ª£c $360 + $160 = $520.\\nV√†o ng√†y th·ª© S√°u, th·ª£ m√°y t√≠nh ƒë∆∞·ª£c $40 x 12 = $480 cho vi·ªác s·ª≠a ch·ªØa c√°c l·ªëp xe h∆°i.\\nDo ƒë√≥, t·ªïng doanh thu c·ªßa th·ª£ m√°y v√†o ng√†y th·ª© S√°u l√† $480.\\nV√¨ v·∫≠y, th·ª£ m√°y ki·∫øm ƒë∆∞·ª£c $520 - $480 = $40 nhi·ªÅu h∆°n v√†o ng√†y th·ª© NƒÉm.',\n",
       "  'answer': '40',\n",
       "  'raw': 'V√†o ng√†y th·ª© NƒÉm, th·ª£ m√°y t√≠nh ƒë∆∞·ª£c $60 x 6 = $360 cho vi·ªác s·ª≠a ch·ªØa c√°c l·ªëp xe t·∫£i.\\nV√†o ng√†y th·ª© NƒÉm, th·ª£ m√°y t√≠nh ƒë∆∞·ª£c $40 x 4 = $160 cho vi·ªác s·ª≠a ch·ªØa c√°c l·ªëp xe h∆°i.\\nT·ªïng c·ªông v√†o ng√†y th·ª© NƒÉm, th·ª£ m√°y ki·∫øm ƒë∆∞·ª£c $360 + $160 = $520.\\nV√†o ng√†y th·ª© S√°u, th·ª£ m√°y t√≠nh ƒë∆∞·ª£c $40 x 12 = $480 cho vi·ªác s·ª≠a ch·ªØa c√°c l·ªëp xe h∆°i.\\nDo ƒë√≥, t·ªïng doanh thu c·ªßa th·ª£ m√°y v√†o ng√†y th·ª© S√°u l√† $480.\\nV√¨ v·∫≠y, th·ª£ m√°y ki·∫øm ƒë∆∞·ª£c $520 - $480 = $40 nhi·ªÅu h∆°n v√†o ng√†y th·ª© NƒÉm.\\n### 40'},\n",
       " {'reasoning': 'Patchy ƒë√£ sinh ra ba l·∫ßn s·ªë l∆∞·ª£ng m√®o con ƒë∆∞·ª£c nh·∫≠n nu√¥i, t·ªïng c·ªông l√† 3 * 7 = 21 con m√®o con. V√¨ v·∫≠y, gia ƒë√¨nh Doubtfire hi·ªán c√≥ 21 + 12 + 7 = 40 con m√®o con.',\n",
       "  'answer': '40',\n",
       "  'raw': 'Patchy ƒë√£ sinh ra ba l·∫ßn s·ªë l∆∞·ª£ng m√®o con ƒë∆∞·ª£c nh·∫≠n nu√¥i, t·ªïng c·ªông l√† 3 * 7 = 21 con m√®o con. V√¨ v·∫≠y, gia ƒë√¨nh Doubtfire hi·ªán c√≥ 21 + 12 + 7 = 40 con m√®o con.\\n### 40'},\n",
       " {'reasoning': 'Sau khi ƒë√£ ƒÉn 2 vi√™n k·∫πo m√∫t, c√≤n l·∫°i 30 - 2 = 28 vi√™n k·∫πo m√∫t. V√¨ m·ªói t√∫i ch·ª©a 2 vi√™n k·∫πo m√∫t, n√™n Jean c√≥ th·ªÉ ƒë√≥ng ƒë∆∞·ª£c 14 t√∫i.',\n",
       "  'answer': '14',\n",
       "  'raw': 'Sau khi ƒë√£ ƒÉn 2 vi√™n k·∫πo m√∫t, c√≤n l·∫°i 30 - 2 = 28 vi√™n k·∫πo m√∫t. V√¨ m·ªói t√∫i ch·ª©a 2 vi√™n k·∫πo m√∫t, n√™n Jean c√≥ th·ªÉ ƒë√≥ng ƒë∆∞·ª£c 14 t√∫i.\\n### 14'},\n",
       " {'reasoning': 'Anh ta ƒëang chi $14 cho m·ªói chuy·∫øn ƒëi (7+7).\\nV·∫≠y anh ta c√≥ th·ªÉ ƒëi xem phim $3 l·∫ßn (42/14 = 3).',\n",
       "  'answer': '3',\n",
       "  'raw': 'Anh ta ƒëang chi $14 cho m·ªói chuy·∫øn ƒëi (7+7).\\nV·∫≠y anh ta c√≥ th·ªÉ ƒëi xem phim $3 l·∫ßn (42/14 = 3).\\n### 3'},\n",
       " {'reasoning': 'Gi·∫£ s·ª≠ p l√† s·ªë l∆∞·ª£ng h·ªôp m√† chi·∫øc xe t·∫£i c√≥ th·ªÉ t·∫£i ƒë∆∞·ª£c.\\nCh√∫ng ta bi·∫øt r·∫±ng 15p + 3755 = 5000.\\nTr·ª´ 3755 t·ª´ c·∫£ hai ph√≠a, ta c√≥: 15p = 1245.\\nChia c·∫£ hai ph√≠a cho 15, ta c√≥: p = 83.',\n",
       "  'answer': '83',\n",
       "  'raw': 'Gi·∫£ s·ª≠ p l√† s·ªë l∆∞·ª£ng h·ªôp m√† chi·∫øc xe t·∫£i c√≥ th·ªÉ t·∫£i ƒë∆∞·ª£c.\\nCh√∫ng ta bi·∫øt r·∫±ng 15p + 3755 = 5000.\\nTr·ª´ 3755 t·ª´ c·∫£ hai ph√≠a, ta c√≥: 15p = 1245.\\nChia c·∫£ hai ph√≠a cho 15, ta c√≥: p = 83.\\n### 83'},\n",
       " {'reasoning': 'Nh√† cung c·∫•p ƒë√£ th√™m ph√≠ $10 cho ph√≠ v·∫≠n chuy·ªÉn (t·ªïng c·ªông 25% tr√™n $40.00).\\nV√¨ v·∫≠y, ph√≠ v·∫≠n chuy·ªÉn l√† $10 + $3 = $13.00.\\nPh√≠ b·ªï sung th√™m v√†o l√† $10 + $4 = $14.00.\\nV·∫≠y gi√° tr·ªã cu·ªëi c√πng c·ªßa t·∫•t c·∫£ c√°c kho·∫£n ph√≠ l√† $14.00.\\nV√¨ v·∫≠y, gi√° tr·ªã cu·ªëi c√πng c·ªßa m√≥n ƒÉn c·ªßa Stephen l√† $40 - $14 = $26.00.',\n",
       "  'answer': '26',\n",
       "  'raw': 'Nh√† cung c·∫•p ƒë√£ th√™m ph√≠ $10 cho ph√≠ v·∫≠n chuy·ªÉn (t·ªïng c·ªông 25% tr√™n $40.00).\\nV√¨ v·∫≠y, ph√≠ v·∫≠n chuy·ªÉn l√† $10 + $3 = $13.00.\\nPh√≠ b·ªï sung th√™m v√†o l√† $10 + $4 = $14.00.\\nV·∫≠y gi√° tr·ªã cu·ªëi c√πng c·ªßa t·∫•t c·∫£ c√°c kho·∫£n ph√≠ l√† $14.00.\\nV√¨ v·∫≠y, gi√° tr·ªã cu·ªëi c√πng c·ªßa m√≥n ƒÉn c·ªßa Stephen l√† $40 - $14 = $26.00.\\n### 26'},\n",
       " {'reasoning': 'C√≥ 120 qu·∫£ m√¢m x√¥i t·ª´ c√°c ch√πm.\\nT·ªïng c·ªông c√≥ 187 qu·∫£ m√¢m x√¥i t·ª´ ch√πm v√† nh·ªØng qu·∫£ ƒë∆°n l·∫ª.',\n",
       "  'answer': '187',\n",
       "  'raw': 'C√≥ 120 qu·∫£ m√¢m x√¥i t·ª´ c√°c ch√πm.\\nT·ªïng c·ªông c√≥ 187 qu·∫£ m√¢m x√¥i t·ª´ ch√πm v√† nh·ªØng qu·∫£ ƒë∆°n l·∫ª.\\n### 187'},\n",
       " {'reasoning': 'N·∫øu c√≥ 1 qu·∫£ cam kh√¥ng t·ªët, 20% s·ªë cam ch∆∞a ch√≠n v√† 2 qu·∫£ cam chua th√¨ t·ªïng s·ªë cam kh√¥ng t·ªët l√† 1+20%+2 = 3.6\\nT·ªïng s·ªë cam t·ªët l√† 25-3.6 = 21.4',\n",
       "  'answer': '21',\n",
       "  'raw': 'N·∫øu c√≥ 1 qu·∫£ cam kh√¥ng t·ªët, 20% s·ªë cam ch∆∞a ch√≠n v√† 2 qu·∫£ cam chua th√¨ t·ªïng s·ªë cam kh√¥ng t·ªët l√† 1+20%+2 = 3.6\\nT·ªïng s·ªë cam t·ªët l√† 25-3.6 = 21.4\\n### 21'},\n",
       " {'reasoning': 'Gi√° c·ªßa b·ªô ƒë·ªì l√† 500 ƒë√¥ la + 800 ƒë√¥ la = 1300 ƒë√¥ la.\\nB·∫£o hi·ªÉm l√† 10% * 1300 ƒë√¥ la = 130 ƒë√¥ la.\\nV·∫≠y t·ªïng s·ªë ti·ªÅn m√† Janet ƒë√£ tr·∫£ l√† 1300 ƒë√¥ la - 130 ƒë√¥ la = 1170 ƒë√¥ la.',\n",
       "  'answer': '1170',\n",
       "  'raw': 'Gi√° c·ªßa b·ªô ƒë·ªì l√† 500 ƒë√¥ la + 800 ƒë√¥ la = 1300 ƒë√¥ la.\\nB·∫£o hi·ªÉm l√† 10% * 1300 ƒë√¥ la = 130 ƒë√¥ la.\\nV·∫≠y t·ªïng s·ªë ti·ªÅn m√† Janet ƒë√£ tr·∫£ l√† 1300 ƒë√¥ la - 130 ƒë√¥ la = 1170 ƒë√¥ la.\\n### 1170'},\n",
       " {'reasoning': 'ƒê·∫ßu ti√™n t√¨m s·ªë nƒÉm c√≤n l·∫°i m√† Marcy s·∫Ω l√†m vi·ªác: 30 nƒÉm - 20 nƒÉm = 10 nƒÉm. Sau ƒë√≥ t√¨m s·ªë ti·ªÅn m√† c√¥ ·∫•y ƒë∆∞·ª£c tr·∫£ m·ªói nƒÉm t·ª´ l∆∞∆°ng h∆∞u c·ªßa m√¨nh: $50,000/nƒÉm * 5% = $2,500/nƒÉm. Ti·∫øp theo nh√¢n s·ªë ƒë√≥ v·ªõi s·ªë nƒÉm c√≤n l·∫°i m√† c√¥ ·∫•y s·∫Ω l√†m vi·ªác: $2,500/nƒÉm * 10 nƒÉm = $25,000/nƒÉm. Cu·ªëi c√πng, c·ªông th√™m kho·∫£n ƒë√≥ v√†o s·ªë ti·ªÅn l∆∞∆°ng h∆∞u c·ªßa c√¥ ·∫•y ƒë·ªÉ t√¨m t·ªïng s·ªë ti·ªÅn m·ªói nƒÉm c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c: $25,000/nƒÉm + $50,000/nƒÉm = $75,000/nƒÉm.',\n",
       "  'answer': '75000',\n",
       "  'raw': 'ƒê·∫ßu ti√™n t√¨m s·ªë nƒÉm c√≤n l·∫°i m√† Marcy s·∫Ω l√†m vi·ªác: 30 nƒÉm - 20 nƒÉm = 10 nƒÉm. Sau ƒë√≥ t√¨m s·ªë ti·ªÅn m√† c√¥ ·∫•y ƒë∆∞·ª£c tr·∫£ m·ªói nƒÉm t·ª´ l∆∞∆°ng h∆∞u c·ªßa m√¨nh: $50,000/nƒÉm * 5% = $2,500/nƒÉm. Ti·∫øp theo nh√¢n s·ªë ƒë√≥ v·ªõi s·ªë nƒÉm c√≤n l·∫°i m√† c√¥ ·∫•y s·∫Ω l√†m vi·ªác: $2,500/nƒÉm * 10 nƒÉm = $25,000/nƒÉm. Cu·ªëi c√πng, c·ªông th√™m kho·∫£n ƒë√≥ v√†o s·ªë ti·ªÅn l∆∞∆°ng h∆∞u c·ªßa c√¥ ·∫•y ƒë·ªÉ t√¨m t·ªïng s·ªë ti·ªÅn m·ªói nƒÉm c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c: $25,000/nƒÉm + $50,000/nƒÉm = $75,000/nƒÉm.\\n### 75000'},\n",
       " {'reasoning': 'N·ª≠a ƒë·∫ßu nƒÉm c√≥ 6 th√°ng, v√¨ v·∫≠y 140*6 = 840 ƒë√¥ la. T√≠nh gi·∫£m gi√° sau ƒë√≥ l√† 10/100*840 = 84 ƒë√¥ la. S·ªë ti·ªÅn c√≤n l·∫°i m√† Aleena ph·∫£i tr·∫£ l√† 840-84 = 756 ƒë√¥ la. T·ªïng s·ªë ti·ªÅn c√¥ ·∫•y tr·∫£ cho d·ªãch v·ª• xem phim tr·ª±c tuy·∫øn l√† 140+756 = 916 ƒë√¥ la.',\n",
       "  'answer': '916',\n",
       "  'raw': 'N·ª≠a ƒë·∫ßu nƒÉm c√≥ 6 th√°ng, v√¨ v·∫≠y 140*6 = 840 ƒë√¥ la. T√≠nh gi·∫£m gi√° sau ƒë√≥ l√† 10/100*840 = 84 ƒë√¥ la. S·ªë ti·ªÅn c√≤n l·∫°i m√† Aleena ph·∫£i tr·∫£ l√† 840-84 = 756 ƒë√¥ la. T·ªïng s·ªë ti·ªÅn c√¥ ·∫•y tr·∫£ cho d·ªãch v·ª• xem phim tr·ª±c tuy·∫øn l√† 140+756 = 916 ƒë√¥ la.\\n### 916'},\n",
       " {'reasoning': 'B√¨nh xƒÉng c·ªßa xe c√≥ th·ªÉ ch·ª©a ƒë∆∞·ª£c 12 gallon xƒÉng.\\nSau khi ƒë·ªï ƒë·∫ßy b√¨nh xƒÉng, c√≤n l·∫°i 2 gallon xƒÉng trong b√¨nh xƒÉng.\\nV·ªõi t·ªëc ƒë·ªô ti√™u th·ª• xƒÉng l√† 4 gallon/gi·ªù, b√¨nh xƒÉng c√≥ th·ªÉ ƒëi ƒë∆∞·ª£c 100 d·∫∑m.\\nDo ƒë√≥, b√¨nh xƒÉng c√≥ th·ªÉ ƒëi ƒë∆∞·ª£c 5 d·∫∑m tr√™n 1 gallon xƒÉng.',\n",
       "  'answer': '5',\n",
       "  'raw': 'B√¨nh xƒÉng c·ªßa xe c√≥ th·ªÉ ch·ª©a ƒë∆∞·ª£c 12 gallon xƒÉng.\\nSau khi ƒë·ªï ƒë·∫ßy b√¨nh xƒÉng, c√≤n l·∫°i 2 gallon xƒÉng trong b√¨nh xƒÉng.\\nV·ªõi t·ªëc ƒë·ªô ti√™u th·ª• xƒÉng l√† 4 gallon/gi·ªù, b√¨nh xƒÉng c√≥ th·ªÉ ƒëi ƒë∆∞·ª£c 100 d·∫∑m.\\nDo ƒë√≥, b√¨nh xƒÉng c√≥ th·ªÉ ƒëi ƒë∆∞·ª£c 5 d·∫∑m tr√™n 1 gallon xƒÉng.\\n### 5'},\n",
       " {'reasoning': 'Anh ·∫•y d√†nh 1 gi·ªù ƒë·ªÉ ƒë·ªçc s√°ch (2/2 = 1). V·∫≠y anh ·∫•y d√†nh t·ªïng c·ªông 3 gi·ªù m·ªói l·∫ßn (1+2=3). V√¨ v·∫≠y, anh ·∫•y d√†nh 12 gi·ªù m·ªói tu·∫ßn (3*4=12). V·∫≠y anh ·∫•y d√†nh t·ªïng c·ªông 48 gi·ªù m·ªói nƒÉm (12*4=48).',\n",
       "  'answer': '48',\n",
       "  'raw': 'Anh ·∫•y d√†nh 1 gi·ªù ƒë·ªÉ ƒë·ªçc s√°ch (2/2 = 1). V·∫≠y anh ·∫•y d√†nh t·ªïng c·ªông 3 gi·ªù m·ªói l·∫ßn (1+2=3). V√¨ v·∫≠y, anh ·∫•y d√†nh 12 gi·ªù m·ªói tu·∫ßn (3*4=12). V·∫≠y anh ·∫•y d√†nh t·ªïng c·ªông 48 gi·ªù m·ªói nƒÉm (12*4=48).\\n### 48'},\n",
       " {'reasoning': 'M·ªói ƒë·ªôi c√≥ 5 c·∫ßu th·ªß + 1 hu·∫•n luy·ªán vi√™n = 6 th√†nh vi√™n. V·∫≠y m·ªói tr∆∞·ªùng ƒë√£ g·ª≠i 2 ƒë·ªôi x 6 th√†nh vi√™n/ƒë·ªôi = 12 th√†nh vi√™n. V√¨ v·∫≠y, 4 tr∆∞·ªùng s·∫Ω g·ª≠i t·ªïng c·ªông 4 x 12 = 48 th√†nh vi√™n.',\n",
       "  'answer': '48',\n",
       "  'raw': 'M·ªói ƒë·ªôi c√≥ 5 c·∫ßu th·ªß + 1 hu·∫•n luy·ªán vi√™n = 6 th√†nh vi√™n. V·∫≠y m·ªói tr∆∞·ªùng ƒë√£ g·ª≠i 2 ƒë·ªôi x 6 th√†nh vi√™n/ƒë·ªôi = 12 th√†nh vi√™n. V√¨ v·∫≠y, 4 tr∆∞·ªùng s·∫Ω g·ª≠i t·ªïng c·ªông 4 x 12 = 48 th√†nh vi√™n.\\n### 48'},\n",
       " {'reasoning': 'C√≥ 140 vi√™n rubi trong h·ªôp (175-35 = 140).\\nV√† c√≥ 280 vi√™n ng·ªçc l·ª•c b·∫£o trong h·ªôp (140*2 = 280).\\nV·∫≠y t·ªïng c·ªông trong h·ªôp c√≥ 695 vi√™n ƒë√° qu√Ω (175+140+280 = 695).',\n",
       "  'answer': '695',\n",
       "  'raw': 'C√≥ 140 vi√™n rubi trong h·ªôp (175-35 = 140).\\nV√† c√≥ 280 vi√™n ng·ªçc l·ª•c b·∫£o trong h·ªôp (140*2 = 280).\\nV·∫≠y t·ªïng c·ªông trong h·ªôp c√≥ 695 vi√™n ƒë√° qu√Ω (175+140+280 = 695).\\n### 695'},\n",
       " {'reasoning': 'N·∫øu c√≥ 60 h·ªçc sinh n·ªØ v√† t·ª∑ l·ªá gi√°o vi√™n so v·ªõi s·ªë h·ªçc sinh l√† 1/5, th√¨ c√≥ 120 gi√°o vi√™n ·ªü tr∆∞·ªùng (5*60=120).\\nT·ªïng s·ªë h·ªçc sinh l√† 60+120=180.\\nS·ªë h·ªçc sinh nam b·∫±ng 2 l·∫ßn s·ªë h·ªçc sinh n·ªØ, t·ª©c l√† c√≥ 2*60=120 h·ªçc sinh nam.\\nC√≥ t·ªïng c·ªông 180 h·ªçc sinh ·ªü tr∆∞·ªùng (120+60=180).',\n",
       "  'answer': '12',\n",
       "  'raw': 'N·∫øu c√≥ 60 h·ªçc sinh n·ªØ v√† t·ª∑ l·ªá gi√°o vi√™n so v·ªõi s·ªë h·ªçc sinh l√† 1/5, th√¨ c√≥ 120 gi√°o vi√™n ·ªü tr∆∞·ªùng (5*60=120).\\nT·ªïng s·ªë h·ªçc sinh l√† 60+120=180.\\nS·ªë h·ªçc sinh nam b·∫±ng 2 l·∫ßn s·ªë h·ªçc sinh n·ªØ, t·ª©c l√† c√≥ 2*60=120 h·ªçc sinh nam.\\nC√≥ t·ªïng c·ªông 180 h·ªçc sinh ·ªü tr∆∞·ªùng (120+60=180).\\n### 12'},\n",
       " {'reasoning': 'Bailey ƒë√£ nh·∫≠n ƒë∆∞·ª£c $5/tu·∫ßn * 8 tu·∫ßn = $40 t·ª´ kho·∫£n tr·ª£ c·∫•p. Sau khi nh·∫≠n ƒë∆∞·ª£c kho·∫£n tr·ª£ c·∫•p, Bailey c√≤n l·∫°i $60 sau khi tr·ª´ ƒëi kho·∫£n tr·ª£ c·∫•p. V√¨ v·∫≠y, Bailey b·∫Øt ƒë·∫ßu v·ªõi $100 - $60 = $40.',\n",
       "  'answer': '40',\n",
       "  'raw': 'Bailey ƒë√£ nh·∫≠n ƒë∆∞·ª£c $5/tu·∫ßn * 8 tu·∫ßn = $40 t·ª´ kho·∫£n tr·ª£ c·∫•p. Sau khi nh·∫≠n ƒë∆∞·ª£c kho·∫£n tr·ª£ c·∫•p, Bailey c√≤n l·∫°i $60 sau khi tr·ª´ ƒëi kho·∫£n tr·ª£ c·∫•p. V√¨ v·∫≠y, Bailey b·∫Øt ƒë·∫ßu v·ªõi $100 - $60 = $40.\\n### 40'},\n",
       " {'reasoning': 'C√¥ ·∫•y d·∫°y 5 l·ªõp nh·∫£y m·ªói ng√†y trong tu·∫ßn v√† 1 l·ªõp v√†o th·ª© B·∫£y, t·ªïng c·ªông l√† 5+1=6 l·ªõp.\\nM·ªói l·ªõp c√≥ 15 h·ªçc sinh n√™n c√¥ ·∫•y c√≥ 6*15=90 h·ªçc sinh m·ªói ng√†y.\\nC√¥ ·∫•y t√≠nh $15.00 cho m·ªói h·ªçc sinh v√† c√¥ ·∫•y c√≥ 90 h·ªçc sinh m·ªói ng√†y n√™n c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c 15*90=$1350.00 m·ªói ng√†y.\\nC√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c $1350.00 m·ªói ng√†y v√† c√¥ ·∫•y d·∫°y h·ªçc 7 ng√†y n√™n c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c 1350*7=$9450.00 m·ªói tu·∫ßn.',\n",
       "  'answer': '9450',\n",
       "  'raw': 'C√¥ ·∫•y d·∫°y 5 l·ªõp nh·∫£y m·ªói ng√†y trong tu·∫ßn v√† 1 l·ªõp v√†o th·ª© B·∫£y, t·ªïng c·ªông l√† 5+1=6 l·ªõp.\\nM·ªói l·ªõp c√≥ 15 h·ªçc sinh n√™n c√¥ ·∫•y c√≥ 6*15=90 h·ªçc sinh m·ªói ng√†y.\\nC√¥ ·∫•y t√≠nh $15.00 cho m·ªói h·ªçc sinh v√† c√¥ ·∫•y c√≥ 90 h·ªçc sinh m·ªói ng√†y n√™n c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c 15*90=$1350.00 m·ªói ng√†y.\\nC√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c $1350.00 m·ªói ng√†y v√† c√¥ ·∫•y d·∫°y h·ªçc 7 ng√†y n√™n c√¥ ·∫•y ki·∫øm ƒë∆∞·ª£c 1350*7=$9450.00 m·ªói tu·∫ßn.\\n### 9450'},\n",
       " {'reasoning': 'N·∫øu c√¥ng th·ª©c ƒë·∫ßu ti√™n c√≥ 20 h∆∞·ªõng d·∫´n, c√¥ng th·ª©c th·ª© hai s·∫Ω c√≥ 2*20 = 40 h∆∞·ªõng d·∫´n. ƒê·ªÉ chu·∫©n b·ªã c·∫£ hai m√≥n ƒÉn, Kelian s·∫Ω c·∫ßn ƒë·ªçc 20+40 = 60 h∆∞·ªõng d·∫´n.',\n",
       "  'answer': '60',\n",
       "  'raw': 'N·∫øu c√¥ng th·ª©c ƒë·∫ßu ti√™n c√≥ 20 h∆∞·ªõng d·∫´n, c√¥ng th·ª©c th·ª© hai s·∫Ω c√≥ 2*20 = 40 h∆∞·ªõng d·∫´n. ƒê·ªÉ chu·∫©n b·ªã c·∫£ hai m√≥n ƒÉn, Kelian s·∫Ω c·∫ßn ƒë·ªçc 20+40 = 60 h∆∞·ªõng d·∫´n.\\n### 60'},\n",
       " {'reasoning': 'S·ªë ti·ªÅn m√† Tommy thu ƒë∆∞·ª£c t·ª´ vi·ªác b√°n b√°nh brownie l√† 43 * $3 = $129.\\nS·ªë ti·ªÅn m√† Tommy thu ƒë∆∞·ª£c t·ª´ vi·ªác b√°n b√°nh ph√¥ mai l√† 23 * $4 = $92.\\nT·ªïng s·ªë ti·ªÅn m√† Tommy thu ƒë∆∞·ª£c t·ª´ vi·ªác b√°n b√°nh brownie v√† b√°nh ph√¥ mai l√† $129 + $92 = $221.',\n",
       "  'answer': '221',\n",
       "  'raw': 'S·ªë ti·ªÅn m√† Tommy thu ƒë∆∞·ª£c t·ª´ vi·ªác b√°n b√°nh brownie l√† 43 * $3 = $129.\\nS·ªë ti·ªÅn m√† Tommy thu ƒë∆∞·ª£c t·ª´ vi·ªác b√°n b√°nh ph√¥ mai l√† 23 * $4 = $92.\\nT·ªïng s·ªë ti·ªÅn m√† Tommy thu ƒë∆∞·ª£c t·ª´ vi·ªác b√°n b√°nh brownie v√† b√°nh ph√¥ mai l√† $129 + $92 = $221.\\n### 221'},\n",
       " {'reasoning': 'M·ªói ƒëi·ªán tho·∫°i c√≥ gi√° $150 v√† l√£i su·∫•t l√† 2% n√™n l√£i su·∫•t cho m·ªôt chi·∫øc ƒëi·ªán tho·∫°i l√† .2 * 150 = $30\\nT·ªïng s·ªë ti·ªÅn cho nƒÉm ƒëi·ªán tho·∫°i l√† $150 * 5 = $750\\nL√£i su·∫•t cho nƒÉm ƒëi·ªán tho·∫°i l√† $30 * 5 = $150\\nT·ªïng s·ªë ti·ªÅn ƒë·ªÉ tr·∫£ l√† $750 + $150 = $900\\nƒêi·ªÅu n√†y s·∫Ω ƒë∆∞·ª£c tr·∫£ trong 3 th√°ng, v√¨ v·∫≠y c√¥ ·∫•y ph·∫£i tr·∫£ $900 / 3 = $300 m·ªói th√°ng.',\n",
       "  'answer': '300',\n",
       "  'raw': 'M·ªói ƒëi·ªán tho·∫°i c√≥ gi√° $150 v√† l√£i su·∫•t l√† 2% n√™n l√£i su·∫•t cho m·ªôt chi·∫øc ƒëi·ªán tho·∫°i l√† .2 * 150 = $30\\nT·ªïng s·ªë ti·ªÅn cho nƒÉm ƒëi·ªán tho·∫°i l√† $150 * 5 = $750\\nL√£i su·∫•t cho nƒÉm ƒëi·ªán tho·∫°i l√† $30 * 5 = $150\\nT·ªïng s·ªë ti·ªÅn ƒë·ªÉ tr·∫£ l√† $750 + $150 = $900\\nƒêi·ªÅu n√†y s·∫Ω ƒë∆∞·ª£c tr·∫£ trong 3 th√°ng, v√¨ v·∫≠y c√¥ ·∫•y ph·∫£i tr·∫£ $900 / 3 = $300 m·ªói th√°ng.\\n### 300'},\n",
       " {'reasoning': 'Anh ta b√°n 12 ch·∫≠u c√∫c v·∫°n th·ªç v·ªõi gi√° $2.74 m·ªói ch·∫≠u n√™n anh ta ki·∫øm ƒë∆∞·ª£c 12 * $2.74 = $32.88. Anh ta b√°n 9 ch·∫≠u hoa c√∫c v·ªõi gi√° $1.87 m·ªói ch·∫≠u n√™n anh ta ki·∫øm ƒë∆∞·ª£c 9 * $1.87 = $16.83. Anh ta b√°n 17 ch·∫≠u hoa Begonia v·ªõi gi√° $2.12 m·ªói ch·∫≠u n√™n anh ta ki·∫øm ƒë∆∞·ª£c 17 * $2.12 = $36.04. T·ªïng s·ªë ti·ªÅn anh ta ki·∫øm ƒë∆∞·ª£c l√† $32.88 + $16.83 + $36.04 = $85.75.',\n",
       "  'answer': '85',\n",
       "  'raw': 'Anh ta b√°n 12 ch·∫≠u c√∫c v·∫°n th·ªç v·ªõi gi√° $2.74 m·ªói ch·∫≠u n√™n anh ta ki·∫øm ƒë∆∞·ª£c 12 * $2.74 = $32.88. Anh ta b√°n 9 ch·∫≠u hoa c√∫c v·ªõi gi√° $1.87 m·ªói ch·∫≠u n√™n anh ta ki·∫øm ƒë∆∞·ª£c 9 * $1.87 = $16.83. Anh ta b√°n 17 ch·∫≠u hoa Begonia v·ªõi gi√° $2.12 m·ªói ch·∫≠u n√™n anh ta ki·∫øm ƒë∆∞·ª£c 17 * $2.12 = $36.04. T·ªïng s·ªë ti·ªÅn anh ta ki·∫øm ƒë∆∞·ª£c l√† $32.88 + $16.83 + $36.04 = $85.75.\\n### 85'},\n",
       " {'reasoning': 'N·∫øu t·∫ßng th·ª© 4 c√≥ di·ªán t√≠ch 16, t·∫ßng th·ª© 3 c√≥ di·ªán t√≠ch l√† 16*2=32.\\nT·∫ßng th·ª© 2 c√≥ di·ªán t√≠ch l√† 32*2=64.\\nT·∫ßng th·ª© 1 c√≥ di·ªán t√≠ch l√† 64*2=128.\\nV·∫≠y t·ªïng di·ªán t√≠ch l√† 128+64+32+16=240.\\nƒêi·ªÅu n√†y c√≥ nghƒ©a l√† trung b√¨nh m·ªói t·∫ßng c√≥ di·ªán t√≠ch l√† 240/4=60.',\n",
       "  'answer': '60',\n",
       "  'raw': 'N·∫øu t·∫ßng th·ª© 4 c√≥ di·ªán t√≠ch 16, t·∫ßng th·ª© 3 c√≥ di·ªán t√≠ch l√† 16*2=32.\\nT·∫ßng th·ª© 2 c√≥ di·ªán t√≠ch l√† 32*2=64.\\nT·∫ßng th·ª© 1 c√≥ di·ªán t√≠ch l√† 64*2=128.\\nV·∫≠y t·ªïng di·ªán t√≠ch l√† 128+64+32+16=240.\\nƒêi·ªÅu n√†y c√≥ nghƒ©a l√† trung b√¨nh m·ªói t·∫ßng c√≥ di·ªán t√≠ch l√† 240/4=60.\\n### 60'},\n",
       " {'reasoning': 'Sau 180 ng√†y ƒë·∫ßu ti√™n, ch√∫ ch√≥ s·∫Ω c·∫ßn 2 ch√©n th·ª©c ƒÉn ch√≥ m·ªói ng√†y, v√¨ v·∫≠y c√¥ ·∫•y s·∫Ω c·∫ßn 2 * 180 = 360 ch√©n th·ª©c ƒÉn ch√≥. C√¥ ·∫•y s·∫Ω s·ª≠ d·ª•ng 360/110 = 3.27 bao th·ª©c ƒÉn ch√≥ trong nƒÉm ƒë·∫ßu ti√™n. Do ƒë√≥, c√¥ ·∫•y s·∫Ω c·∫ßn th√™m 4 bao th·ª©c ƒÉn ch√≥ sau khi ƒë√£ s·ª≠ d·ª•ng h·∫øt 3.27 bao.',\n",
       "  'answer': '4',\n",
       "  'raw': 'Sau 180 ng√†y ƒë·∫ßu ti√™n, ch√∫ ch√≥ s·∫Ω c·∫ßn 2 ch√©n th·ª©c ƒÉn ch√≥ m·ªói ng√†y, v√¨ v·∫≠y c√¥ ·∫•y s·∫Ω c·∫ßn 2 * 180 = 360 ch√©n th·ª©c ƒÉn ch√≥. C√¥ ·∫•y s·∫Ω s·ª≠ d·ª•ng 360/110 = 3.27 bao th·ª©c ƒÉn ch√≥ trong nƒÉm ƒë·∫ßu ti√™n. Do ƒë√≥, c√¥ ·∫•y s·∫Ω c·∫ßn th√™m 4 bao th·ª©c ƒÉn ch√≥ sau khi ƒë√£ s·ª≠ d·ª•ng h·∫øt 3.27 bao.\\n### 4'},\n",
       " {'reasoning': 'S·ªë pound qu·∫ßn √°o m√† David gi·∫∑t l√† 400/4 = 100 pound.\\nRaymond gi·∫∑t g·∫•p ƒë√¥i s·ªë l∆∞·ª£ng qu·∫ßn √°o c·ªßa David, v√¨ v·∫≠y anh ta gi·∫∑t 2 * 100 = 200 pound qu·∫ßn √°o.\\nV√¨ David gi·∫∑t 100 pound qu·∫ßn √°o, n√™n s·ª± kh√°c bi·ªát gi·ªØa s·ªë l∆∞·ª£ng qu·∫ßn √°o m√† anh ta gi·∫∑t v√† s·ªë l∆∞·ª£ng qu·∫ßn √°o m√† Raymond gi·∫∑t l√† 200 - 100 = 100 pound.',\n",
       "  'answer': '100',\n",
       "  'raw': 'S·ªë pound qu·∫ßn √°o m√† David gi·∫∑t l√† 400/4 = 100 pound.\\nRaymond gi·∫∑t g·∫•p ƒë√¥i s·ªë l∆∞·ª£ng qu·∫ßn √°o c·ªßa David, v√¨ v·∫≠y anh ta gi·∫∑t 2 * 100 = 200 pound qu·∫ßn √°o.\\nV√¨ David gi·∫∑t 100 pound qu·∫ßn √°o, n√™n s·ª± kh√°c bi·ªát gi·ªØa s·ªë l∆∞·ª£ng qu·∫ßn √°o m√† anh ta gi·∫∑t v√† s·ªë l∆∞·ª£ng qu·∫ßn √°o m√† Raymond gi·∫∑t l√† 200 - 100 = 100 pound.\\n### 100'},\n",
       " {'reasoning': 'Anh ta c√≥ th·ªÉ mua 6 g√≥i c√≥ 3 b√¥ng hoa trong m·ªói g√≥i v·ªõi gi√° $2.50/g√≥i * 6 = $15.00.\\nV·∫≠y c√≤n l·∫°i 12 b√¥ng hoa.\\nAnh ta c√≥ th·ªÉ mua 6 g√≥i c√≥ 2 b√¥ng hoa trong m·ªói g√≥i v·ªõi gi√° $1.00/g√≥i * 6 = $6.00.\\nV·∫≠y c√≤n l·∫°i 6 b√¥ng hoa.\\nƒêi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† anh ta c√≥ th·ªÉ mua 18 b√¥ng hoa v·ªõi gi√° $15.00 + $6.00 = $21.00.\\nV·∫≠y anh ta c√≥ th·ªÉ mua 18 b√¥ng hoa v·ªõi gi√° $2.50/g√≥i * 6 + $1.00/g√≥i * 6 = $21.00.\\nV√¨ v·∫≠y, anh ta ti·∫øt ki·ªám ƒë∆∞·ª£c $25.00 - $21.00 = $4.00.',\n",
       "  'answer': '4',\n",
       "  'raw': 'Anh ta c√≥ th·ªÉ mua 6 g√≥i c√≥ 3 b√¥ng hoa trong m·ªói g√≥i v·ªõi gi√° $2.50/g√≥i * 6 = $15.00.\\nV·∫≠y c√≤n l·∫°i 12 b√¥ng hoa.\\nAnh ta c√≥ th·ªÉ mua 6 g√≥i c√≥ 2 b√¥ng hoa trong m·ªói g√≥i v·ªõi gi√° $1.00/g√≥i * 6 = $6.00.\\nV·∫≠y c√≤n l·∫°i 6 b√¥ng hoa.\\nƒêi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† anh ta c√≥ th·ªÉ mua 18 b√¥ng hoa v·ªõi gi√° $15.00 + $6.00 = $21.00.\\nV·∫≠y anh ta c√≥ th·ªÉ mua 18 b√¥ng hoa v·ªõi gi√° $2.50/g√≥i * 6 + $1.00/g√≥i * 6 = $21.00.\\nV√¨ v·∫≠y, anh ta ti·∫øt ki·ªám ƒë∆∞·ª£c $25.00 - $21.00 = $4.00.\\n### 4'},\n",
       " {'reasoning': 'Gi·∫£m gi√° l√† 100*.3=$30\\nV·∫≠y chi ph√≠ l√† 100-30=$70',\n",
       "  'answer': '70',\n",
       "  'raw': 'Gi·∫£m gi√° l√† 100*.3=$30\\nV·∫≠y chi ph√≠ l√† 100-30=$70\\n### 70'},\n",
       " {'reasoning': 'Hai c√¥ g√°i c√πng c√≥ 24 x 1/6 = 4 l√≠t n∆∞·ªõc.\\nC·∫£ ba c√πng c√≥ 4 + 6 = 10 l√≠t n∆∞·ªõc.\\nSau ƒë√≥ c√≤n l·∫°i 24 - 10 = 14 l√≠t n∆∞·ªõc.',\n",
       "  'answer': '14',\n",
       "  'raw': 'Hai c√¥ g√°i c√πng c√≥ 24 x 1/6 = 4 l√≠t n∆∞·ªõc.\\nC·∫£ ba c√πng c√≥ 4 + 6 = 10 l√≠t n∆∞·ªõc.\\nSau ƒë√≥ c√≤n l·∫°i 24 - 10 = 14 l√≠t n∆∞·ªõc.\\n### 14'},\n",
       " {'reasoning': 'Charlie b·∫Øt ƒë·∫ßu v·ªõi 10 tem v√† mua th√™m 21 tem n·ªØa, t·ªïng c·ªông l√† 10+21 = 31 tem.\\nAnh ta c≈©ng nh·∫≠n ƒë∆∞·ª£c 23 tem trong sinh nh·∫≠t v√† 9 tem cho em g√°i c·ªßa m√¨nh, t·ªïng c·ªông l√† 31+23+9 = 63 tem.\\nCharlie ƒë√£ d√πng 28 tem cho thi·ªáp ch√∫c m·ª´ng v√† c√≤n l·∫°i 63-28 = 35 tem.',\n",
       "  'answer': '35',\n",
       "  'raw': 'Charlie b·∫Øt ƒë·∫ßu v·ªõi 10 tem v√† mua th√™m 21 tem n·ªØa, t·ªïng c·ªông l√† 10+21 = 31 tem.\\nAnh ta c≈©ng nh·∫≠n ƒë∆∞·ª£c 23 tem trong sinh nh·∫≠t v√† 9 tem cho em g√°i c·ªßa m√¨nh, t·ªïng c·ªông l√† 31+23+9 = 63 tem.\\nCharlie ƒë√£ d√πng 28 tem cho thi·ªáp ch√∫c m·ª´ng v√† c√≤n l·∫°i 63-28 = 35 tem.\\n### 35'},\n",
       " {'reasoning': 'Alex n·∫∑ng 123 pound v√¨ 4 x 125 - 2 = 123.\\nT·ªïng c√¢n n·∫∑ng c·ªßa h·ªç l√† 248 pound v√¨ 125 + 123 = 248.',\n",
       "  'answer': '248',\n",
       "  'raw': 'Alex n·∫∑ng 123 pound v√¨ 4 x 125 - 2 = 123.\\nT·ªïng c√¢n n·∫∑ng c·ªßa h·ªç l√† 248 pound v√¨ 125 + 123 = 248.\\n### 248'},\n",
       " {'reasoning': 'C√≥ t·ªïng c·ªông 75 b√¥ng hoa trong v∆∞·ªùn hoa.\\nT·ªïng s·ªë gai l√† 600.',\n",
       "  'answer': '600',\n",
       "  'raw': 'C√≥ t·ªïng c·ªông 75 b√¥ng hoa trong v∆∞·ªùn hoa.\\nT·ªïng s·ªë gai l√† 600.\\n### 600'},\n",
       " {'reasoning': 'S·ªë tr·∫≠n th·∫Øng l√† x.\\nS·ªë tr·∫≠n thua l√† x-8.\\nT·ªïng s·ªë tr·∫≠n l√† x+x-8=22.\\n2x-8=22\\n2x=30\\nx=15\\nS·ªë tr·∫≠n th·∫Øng l√† 15.',\n",
       "  'answer': '15',\n",
       "  'raw': 'S·ªë tr·∫≠n th·∫Øng l√† x.\\nS·ªë tr·∫≠n thua l√† x-8.\\nT·ªïng s·ªë tr·∫≠n l√† x+x-8=22.\\n2x-8=22\\n2x=30\\nx=15\\nS·ªë tr·∫≠n th·∫Øng l√† 15.\\n### 15'},\n",
       " {'reasoning': 'Anh ta ƒë√£ ƒëi ngh·ªâ t·ª´ khi 23 tu·ªïi v√† hi·ªán t·∫°i l√† 34 tu·ªïi, v√¨ v·∫≠y anh ta ƒë√£ ƒëi ngh·ªâ trong 11 nƒÉm. Anh ta ƒë√£ ƒëi ngh·ªâ 4 l·∫ßn m·ªói nƒÉm, v√¨ v·∫≠y anh ta c√≥ 44 chi·∫øc √°o thun. M·ªói chi·∫øc √°o thun l√† m·ªôt kh·ªëi chƒÉn, v√¨ v·∫≠y anh ta c√≥ 44 kh·ªëi chƒÉn.',\n",
       "  'answer': '44',\n",
       "  'raw': 'Anh ta ƒë√£ ƒëi ngh·ªâ t·ª´ khi 23 tu·ªïi v√† hi·ªán t·∫°i l√† 34 tu·ªïi, v√¨ v·∫≠y anh ta ƒë√£ ƒëi ngh·ªâ trong 11 nƒÉm. Anh ta ƒë√£ ƒëi ngh·ªâ 4 l·∫ßn m·ªói nƒÉm, v√¨ v·∫≠y anh ta c√≥ 44 chi·∫øc √°o thun. M·ªói chi·∫øc √°o thun l√† m·ªôt kh·ªëi chƒÉn, v√¨ v·∫≠y anh ta c√≥ 44 kh·ªëi chƒÉn.\\n### 44'},\n",
       " {'reasoning': 'L·∫ßn th·ª© hai n√≥ reo trong 3 l·∫ßn so v·ªõi 4 l·∫ßn, t·ªïng c·ªông l√† 12 l·∫ßn.\\nV·∫≠y sau hai l·∫ßn n√≥ reo l√† 16 l·∫ßn.\\nSau ƒë√≥, sau khi t·∫Øt, n√≥ l·∫°i ƒë∆∞·ª£c k√≠ch ho·∫°t v√† b·∫Øt ƒë·∫ßu t·ª´ l·∫°i.\\nDo ƒë√≥, sau 3 l·∫ßn n√≥ ƒë√£ ƒë∆∞·ª£c k√≠ch ho·∫°t, n√≥ ƒë√£ ph√°t ra 52 l·∫ßn.',\n",
       "  'answer': '52',\n",
       "  'raw': 'L·∫ßn th·ª© hai n√≥ reo trong 3 l·∫ßn so v·ªõi 4 l·∫ßn, t·ªïng c·ªông l√† 12 l·∫ßn.\\nV·∫≠y sau hai l·∫ßn n√≥ reo l√† 16 l·∫ßn.\\nSau ƒë√≥, sau khi t·∫Øt, n√≥ l·∫°i ƒë∆∞·ª£c k√≠ch ho·∫°t v√† b·∫Øt ƒë·∫ßu t·ª´ l·∫°i.\\nDo ƒë√≥, sau 3 l·∫ßn n√≥ ƒë√£ ƒë∆∞·ª£c k√≠ch ho·∫°t, n√≥ ƒë√£ ph√°t ra 52 l·∫ßn.\\n### 52'},\n",
       " {'reasoning': 'Sau nƒÉm ƒë·∫ßu ti√™n, Sylvie nh·∫≠n ƒë∆∞·ª£c m·ªôt kho·∫£n tƒÉng l∆∞∆°ng l√† 600*0.1=$60. V√¨ v·∫≠y, m·ª©c l∆∞∆°ng c·ªßa c√¥ ·∫•y l√† 600+60=$660.\\nƒê·ªëi v·ªõi nƒÉm th·ª© hai, c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c m·ªôt kho·∫£n tƒÉng l∆∞∆°ng l√† 660*0.1=$66. V√¨ v·∫≠y, m·ª©c l∆∞∆°ng c·ªßa c√¥ ·∫•y l√† 660+66=$726.\\nƒê·ªëi v·ªõi nƒÉm th·ª© ba, c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c m·ªôt kho·∫£n tƒÉng l∆∞∆°ng l√† 726*0.1=$72.6. V√¨ v·∫≠y, m·ª©c l∆∞∆°ng c·ªßa c√¥ ·∫•y l√† 726+72.6=$798.6.\\nƒê·ªëi v·ªõi nƒÉm th·ª© t∆∞, c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c m·ªôt kho·∫£n tƒÉng l∆∞∆°ng l√† 798.6*0.1=$79.86. V√¨ v·∫≠y, m·ª©c l∆∞∆°ng c·ªßa c√¥ ·∫•y l√† 798.6+79.86=$878.46.\\nƒê·ªëi v·ªõi nƒÉm th·ª© nƒÉm, c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c m·ªôt kho·∫£n tƒÉng l∆∞∆°ng l√† 878.46*0.1=$87.846. V√¨ v·∫≠y, m·ª©c l∆∞∆°ng c·ªßa c√¥ ·∫•y l√† 878.46+87.846=$966.306.\\nC√≥ th·ªÉ c√≥ s·ª± kh√°c bi·ªát nh·ªè gi·ªØa s·ªë ti·ªÅn n√†y v√† $966.3 v√¨ khi t√≠nh t·ª∑ l·ªá 10%, ta ch·ªâ l·∫•y s·ªë ti·ªÅn ƒë√≥ ƒëi t·ª´ s·ªë ti·ªÅn g·ªëc, kh√¥ng ph·∫£i c·ªông l·∫°i. Do ƒë√≥, s·ªë ti·ªÅn $966.306 m√† Sylvie nh·∫≠n ƒë∆∞·ª£c l√† 966.306-600=$366.306.',\n",
       "  'answer': '366306',\n",
       "  'raw': 'Sau nƒÉm ƒë·∫ßu ti√™n, Sylvie nh·∫≠n ƒë∆∞·ª£c m·ªôt kho·∫£n tƒÉng l∆∞∆°ng l√† 600*0.1=$60. V√¨ v·∫≠y, m·ª©c l∆∞∆°ng c·ªßa c√¥ ·∫•y l√† 600+60=$660.\\nƒê·ªëi v·ªõi nƒÉm th·ª© hai, c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c m·ªôt kho·∫£n tƒÉng l∆∞∆°ng l√† 660*0.1=$66. V√¨ v·∫≠y, m·ª©c l∆∞∆°ng c·ªßa c√¥ ·∫•y l√† 660+66=$726.\\nƒê·ªëi v·ªõi nƒÉm th·ª© ba, c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c m·ªôt kho·∫£n tƒÉng l∆∞∆°ng l√† 726*0.1=$72.6. V√¨ v·∫≠y, m·ª©c l∆∞∆°ng c·ªßa c√¥ ·∫•y l√† 726+72.6=$798.6.\\nƒê·ªëi v·ªõi nƒÉm th·ª© t∆∞, c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c m·ªôt kho·∫£n tƒÉng l∆∞∆°ng l√† 798.6*0.1=$79.86. V√¨ v·∫≠y, m·ª©c l∆∞∆°ng c·ªßa c√¥ ·∫•y l√† 798.6+79.86=$878.46.\\nƒê·ªëi v·ªõi nƒÉm th·ª© nƒÉm, c√¥ ·∫•y nh·∫≠n ƒë∆∞·ª£c m·ªôt kho·∫£n tƒÉng l∆∞∆°ng l√† 878.46*0.1=$87.846. V√¨ v·∫≠y, m·ª©c l∆∞∆°ng c·ªßa c√¥ ·∫•y l√† 878.46+87.846=$966.306.\\nC√≥ th·ªÉ c√≥ s·ª± kh√°c bi·ªát nh·ªè gi·ªØa s·ªë ti·ªÅn n√†y v√† $966.3 v√¨ khi t√≠nh t·ª∑ l·ªá 10%, ta ch·ªâ l·∫•y s·ªë ti·ªÅn ƒë√≥ ƒëi t·ª´ s·ªë ti·ªÅn g·ªëc, kh√¥ng ph·∫£i c·ªông l·∫°i. Do ƒë√≥, s·ªë ti·ªÅn $966.306 m√† Sylvie nh·∫≠n ƒë∆∞·ª£c l√† 966.306-600=$366.306.\\n### 366306'},\n",
       " {'reasoning': 'S·ªë l∆∞·ª£ng b·∫£n sao m√† Marilyn ƒë√£ b√°n l√† 88.000 - s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n = 10 * s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n. V·∫≠y 88.000 - s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n = 10 * s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n. Do ƒë√≥, 88.000 = 11 * s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n. V√¨ v·∫≠y, 88.000/11 = 8.000 = s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n.',\n",
       "  'answer': '8000',\n",
       "  'raw': 'S·ªë l∆∞·ª£ng b·∫£n sao m√† Marilyn ƒë√£ b√°n l√† 88.000 - s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n = 10 * s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n. V·∫≠y 88.000 - s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n = 10 * s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n. Do ƒë√≥, 88.000 = 11 * s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n. V√¨ v·∫≠y, 88.000/11 = 8.000 = s·ªë l∆∞·ª£ng b·∫£n sao m√† Harald ƒë√£ b√°n.\\n### 8000'},\n",
       " {'reasoning': 'C√¥ ·∫•y ƒë√£ m·ªùi 16 ng∆∞·ªùi b·∫°n n√™n 3/4 s·ªë ng∆∞·ªùi s·∫Ω ƒë·∫øn d·ª± ti·ªác sinh nh·∫≠t c·ªßa c√¥ ·∫•y. 16 x 3/4 = 12 ng∆∞·ªùi s·∫Ω ƒë·∫øn d·ª± ti·ªác sinh nh·∫≠t c·ªßa c√¥ ·∫•y. M·ªói ng∆∞·ªùi s·∫Ω nh·∫≠n ƒë∆∞·ª£c .75 t√∫i qu√† t·∫∑ng v√¨ c√¥ ·∫•y ƒë√£ m·ªùi 16 ng∆∞·ªùi b·∫°n. C√¥ ·∫•y s·∫Ω c·∫ßn 9 t√∫i qu√† t·∫∑ng v√¨ 12 x .75 = 9. M·ªói t√∫i qu√† t·∫∑ng c√≥ gi√° $2 v√¨ c√¥ ·∫•y mu·ªën t√≠nh ti·ªÅn m·ªói t√∫i. C√¥ ·∫•y s·∫Ω t·ªën $18 v√¨ 9 x $2 = $18.',\n",
       "  'answer': '18',\n",
       "  'raw': 'C√¥ ·∫•y ƒë√£ m·ªùi 16 ng∆∞·ªùi b·∫°n n√™n 3/4 s·ªë ng∆∞·ªùi s·∫Ω ƒë·∫øn d·ª± ti·ªác sinh nh·∫≠t c·ªßa c√¥ ·∫•y. 16 x 3/4 = 12 ng∆∞·ªùi s·∫Ω ƒë·∫øn d·ª± ti·ªác sinh nh·∫≠t c·ªßa c√¥ ·∫•y. M·ªói ng∆∞·ªùi s·∫Ω nh·∫≠n ƒë∆∞·ª£c .75 t√∫i qu√† t·∫∑ng v√¨ c√¥ ·∫•y ƒë√£ m·ªùi 16 ng∆∞·ªùi b·∫°n. C√¥ ·∫•y s·∫Ω c·∫ßn 9 t√∫i qu√† t·∫∑ng v√¨ 12 x .75 = 9. M·ªói t√∫i qu√† t·∫∑ng c√≥ gi√° $2 v√¨ c√¥ ·∫•y mu·ªën t√≠nh ti·ªÅn m·ªói t√∫i. C√¥ ·∫•y s·∫Ω t·ªën $18 v√¨ 9 x $2 = $18.\\n### 18'},\n",
       " {'reasoning': 'S·ªë l∆∞·ª£ng khoai t√¢y m√† m·ªôt ng∆∞·ªùi l·ªõn s·∫Ω ƒÉn l√† 10 pound. S·∫Ω c√≥ 20 ng∆∞·ªùi l·ªõn, v√¨ v·∫≠y t·ªïng c·ªông s·∫Ω c√≥ 20 * 10 = 200 pound khoai t√¢y cho ng∆∞·ªùi l·ªõn. S·∫Ω c√≥ 5 tr·∫ª em, v√† tr·∫ª em ƒÉn m·ªôt n·ª≠a l∆∞·ª£ng c·ªßa ng∆∞·ªùi l·ªõn, v√¨ v·∫≠y tr·∫ª em s·∫Ω ƒÉn 10 / 2 = 5 pound khoai t√¢y. T·ªïng c·ªông, Ted c·∫ßn 200 + 5 = 205 pound khoai t√¢y.',\n",
       "  'answer': '205',\n",
       "  'raw': 'S·ªë l∆∞·ª£ng khoai t√¢y m√† m·ªôt ng∆∞·ªùi l·ªõn s·∫Ω ƒÉn l√† 10 pound. S·∫Ω c√≥ 20 ng∆∞·ªùi l·ªõn, v√¨ v·∫≠y t·ªïng c·ªông s·∫Ω c√≥ 20 * 10 = 200 pound khoai t√¢y cho ng∆∞·ªùi l·ªõn. S·∫Ω c√≥ 5 tr·∫ª em, v√† tr·∫ª em ƒÉn m·ªôt n·ª≠a l∆∞·ª£ng c·ªßa ng∆∞·ªùi l·ªõn, v√¨ v·∫≠y tr·∫ª em s·∫Ω ƒÉn 10 / 2 = 5 pound khoai t√¢y. T·ªïng c·ªông, Ted c·∫ßn 200 + 5 = 205 pound khoai t√¢y.\\n### 205'},\n",
       " {'reasoning': 'Marcia c√≥ 4 + 2 = 6 v·∫≠t nu√¥i.\\nJan c√≥ 3 * 6 = 18 v·∫≠t nu√¥i.\\nT·ªïng s·ªë v·∫≠t nu√¥i c·ªßa h·ªç l√† 18 + 6 + 4 = 28.',\n",
       "  'answer': '28',\n",
       "  'raw': 'Marcia c√≥ 4 + 2 = 6 v·∫≠t nu√¥i.\\nJan c√≥ 3 * 6 = 18 v·∫≠t nu√¥i.\\nT·ªïng s·ªë v·∫≠t nu√¥i c·ªßa h·ªç l√† 18 + 6 + 4 = 28.\\n### 28'},\n",
       " {'reasoning': 'N·∫øu James nh·ªè h∆°n Corey m·ªôt tu·ªïi, th√¨ Corey s·∫Ω l√† 10+1=11 tu·ªïi.\\nV√¨ Amy nh·ªè h∆°n Corey hai tu·ªïi, n√™n Amy s·∫Ω l√† 11-2=9 tu·ªïi.\\nV√¨ Amy l·ªõn h∆°n Jackson nƒÉm tu·ªïi, n√™n Jackson s·∫Ω l√† 9-5=4 tu·ªïi.',\n",
       "  'answer': '4',\n",
       "  'raw': 'N·∫øu James nh·ªè h∆°n Corey m·ªôt tu·ªïi, th√¨ Corey s·∫Ω l√† 10+1=11 tu·ªïi.\\nV√¨ Amy nh·ªè h∆°n Corey hai tu·ªïi, n√™n Amy s·∫Ω l√† 11-2=9 tu·ªïi.\\nV√¨ Amy l·ªõn h∆°n Jackson nƒÉm tu·ªïi, n√™n Jackson s·∫Ω l√† 9-5=4 tu·ªïi.\\n### 4'},\n",
       " {'reasoning': 'Gerald tr∆∞·ªõc ƒë√¢y m·∫•t 36 gi√¢y ƒë·ªÉ ch·∫°y qua r√†o.\\nSau khi ƒÉn u·ªëng, Gerald m·∫•t 32 gi√¢y ƒë·ªÉ ch·∫°y qua r√†o.',\n",
       "  'answer': '32',\n",
       "  'raw': 'Gerald tr∆∞·ªõc ƒë√¢y m·∫•t 36 gi√¢y ƒë·ªÉ ch·∫°y qua r√†o.\\nSau khi ƒÉn u·ªëng, Gerald m·∫•t 32 gi√¢y ƒë·ªÉ ch·∫°y qua r√†o.\\n### 32'},\n",
       " {'reasoning': 'C√≥ 2 con m√®o cho m·ªói con ch√≥, v√¨ v·∫≠y v·ªõi 60 con ch√≥, c√≥ t·ªïng c·ªông 60*2 = 120 con m√®o.\\nT·ªïng s·ªë m√®o v√† ch√≥ trong khu ph·ªë l√† 120+60 = 180.\\nS·ªë th·ªè trong khu ph·ªë l√† 12 nh·ªè h∆°n t·ªïng s·ªë m√®o v√† ch√≥, t·ª©c l√† c√≥ 180-12 = 168 con th·ªè trong khu ph·ªë.\\nT·ªïng s·ªë th√∫ c∆∞ng trong khu ph·ªë l√† 168+180 = 348.',\n",
       "  'answer': '348',\n",
       "  'raw': 'C√≥ 2 con m√®o cho m·ªói con ch√≥, v√¨ v·∫≠y v·ªõi 60 con ch√≥, c√≥ t·ªïng c·ªông 60*2 = 120 con m√®o.\\nT·ªïng s·ªë m√®o v√† ch√≥ trong khu ph·ªë l√† 120+60 = 180.\\nS·ªë th·ªè trong khu ph·ªë l√† 12 nh·ªè h∆°n t·ªïng s·ªë m√®o v√† ch√≥, t·ª©c l√† c√≥ 180-12 = 168 con th·ªè trong khu ph·ªë.\\nT·ªïng s·ªë th√∫ c∆∞ng trong khu ph·ªë l√† 168+180 = 348.\\n### 348'},\n",
       " {'reasoning': 'C√≥ 200 x 2/5 = 80 nam.\\nV·∫≠y c√≥ 200 - 80 = 120 n·ªØ.\\nƒêi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† c√≥ 120 x 2/3 = 80 n·ªØ tham gia h·ªôi h∆∞·ªõng ƒë·∫°o n·ªØ.\\nDo ƒë√≥, c√≥ 120 - 80 = 40 n·ªØ kh√¥ng tham gia h·ªôi h∆∞·ªõng ƒë·∫°o n·ªØ.',\n",
       "  'answer': '40',\n",
       "  'raw': 'C√≥ 200 x 2/5 = 80 nam.\\nV·∫≠y c√≥ 200 - 80 = 120 n·ªØ.\\nƒêi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† c√≥ 120 x 2/3 = 80 n·ªØ tham gia h·ªôi h∆∞·ªõng ƒë·∫°o n·ªØ.\\nDo ƒë√≥, c√≥ 120 - 80 = 40 n·ªØ kh√¥ng tham gia h·ªôi h∆∞·ªõng ƒë·∫°o n·ªØ.\\n### 40'},\n",
       " {'reasoning': 'James ng·ªß ƒë∆∞·ª£c 180 ph√∫t / 3 = 60 ph√∫t = 1 gi·ªù.\\nV√¨ v·∫≠y, James ng·ªß ƒë∆∞·ª£c 6 gi·ªù.\\nDo ƒë√≥, Harry ng·ªß ƒë∆∞·ª£c 9 gi·ªù - 6 gi·ªù = 3 gi·ªù nhi·ªÅu h∆°n James.',\n",
       "  'answer': '3',\n",
       "  'raw': 'James ng·ªß ƒë∆∞·ª£c 180 ph√∫t / 3 = 60 ph√∫t = 1 gi·ªù.\\nV√¨ v·∫≠y, James ng·ªß ƒë∆∞·ª£c 6 gi·ªù.\\nDo ƒë√≥, Harry ng·ªß ƒë∆∞·ª£c 9 gi·ªù - 6 gi·ªù = 3 gi·ªù nhi·ªÅu h∆°n James.\\n### 3'},\n",
       " {'reasoning': 'Sau khi n·∫•u, 1/2*32 = 16 ounce s·ªët c√† chua c√≤n l·∫°i.\\nFreda ƒë√£ s·ª≠ d·ª•ng 16 ounce s·ªët c√† chua v√† m·ªói lon c√≥ 16 ounce n√™n c√¥ ·∫•y ƒë√£ s·ª≠ d·ª•ng 1 lon.\\nV√¨ m·ªói lon c√≥ 3 qu·∫£ c√† chua n√™n Freda ƒë√£ s·ª≠ d·ª•ng 3 qu·∫£ c√† chua.',\n",
       "  'answer': '3',\n",
       "  'raw': 'Sau khi n·∫•u, 1/2*32 = 16 ounce s·ªët c√† chua c√≤n l·∫°i.\\nFreda ƒë√£ s·ª≠ d·ª•ng 16 ounce s·ªët c√† chua v√† m·ªói lon c√≥ 16 ounce n√™n c√¥ ·∫•y ƒë√£ s·ª≠ d·ª•ng 1 lon.\\nV√¨ m·ªói lon c√≥ 3 qu·∫£ c√† chua n√™n Freda ƒë√£ s·ª≠ d·ª•ng 3 qu·∫£ c√† chua.\\n### 3'},\n",
       " {'reasoning': 'Ban ƒë·∫ßu c√≥ 30 chi·∫øc xe tr√™n ƒë∆∞·ªùng cao t·ªëc v√† 5 chi·∫øc xe r·ªùi ƒëi, v√¨ v·∫≠y c√≤n l·∫°i 30 - 5 = 25 chi·∫øc xe tr√™n ƒë∆∞·ªùng cao t·ªëc.\\nTrong 15 ph√∫t ƒë·∫ßu ti√™n, c√≥ 25 chi·∫øc xe l√°i qua t·∫Øc ƒë∆∞·ªùng v√† 20 chi·∫øc xe l√°i qua t·∫Øc ƒë∆∞·ªùng sau ƒë√≥, t·ªïng c·ªông l√† 25 + 20 = 45 chi·∫øc xe l√°i qua t·∫Øc ƒë∆∞·ªùng.',\n",
       "  'answer': '45',\n",
       "  'raw': 'Ban ƒë·∫ßu c√≥ 30 chi·∫øc xe tr√™n ƒë∆∞·ªùng cao t·ªëc v√† 5 chi·∫øc xe r·ªùi ƒëi, v√¨ v·∫≠y c√≤n l·∫°i 30 - 5 = 25 chi·∫øc xe tr√™n ƒë∆∞·ªùng cao t·ªëc.\\nTrong 15 ph√∫t ƒë·∫ßu ti√™n, c√≥ 25 chi·∫øc xe l√°i qua t·∫Øc ƒë∆∞·ªùng v√† 20 chi·∫øc xe l√°i qua t·∫Øc ƒë∆∞·ªùng sau ƒë√≥, t·ªïng c·ªông l√† 25 + 20 = 45 chi·∫øc xe l√°i qua t·∫Øc ƒë∆∞·ªùng.\\n### 45'},\n",
       " {'reasoning': 'C√¥ ·∫•y hi·ªán c√≥ 2 ch·∫≠u trong 40 gi√° ƒë·ª° n√™n c√¥ ·∫•y c√≥ t·ªïng c·ªông 80 ch·∫≠u c√¢y.\\nSau khi t·∫∑ng ƒëi m·ªôt ch·∫≠u c√¢y, c√¥ ·∫•y s·∫Ω c√≤n l·∫°i 79 ch·∫≠u c√¢y.',\n",
       "  'answer': '79',\n",
       "  'raw': 'C√¥ ·∫•y hi·ªán c√≥ 2 ch·∫≠u trong 40 gi√° ƒë·ª° n√™n c√¥ ·∫•y c√≥ t·ªïng c·ªông 80 ch·∫≠u c√¢y.\\nSau khi t·∫∑ng ƒëi m·ªôt ch·∫≠u c√¢y, c√¥ ·∫•y s·∫Ω c√≤n l·∫°i 79 ch·∫≠u c√¢y.\\n### 79'}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f91513fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating ROUGE scores on reasoning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ROUGE: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 653.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUGE Scores:\n",
      "\n",
      "rouge1:\n",
      "  precision: 0.6416\n",
      "  recall: 0.6285\n",
      "  fmeasure: 0.5971\n",
      "\n",
      "rouge2:\n",
      "  precision: 0.3492\n",
      "  recall: 0.3439\n",
      "  fmeasure: 0.3259\n",
      "\n",
      "rougeL:\n",
      "  precision: 0.4649\n",
      "  recall: 0.4525\n",
      "  fmeasure: 0.4308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROUGE scores\n",
    "print(\"\\nCalculating ROUGE scores on reasoning...\")\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Initialize\n",
    "rouge_scores = {\n",
    "    'rouge1': {'precision': 0.0, 'recall': 0.0, 'fmeasure': 0.0},\n",
    "    'rouge2': {'precision': 0.0, 'recall': 0.0, 'fmeasure': 0.0},\n",
    "    'rougeL': {'precision': 0.0, 'recall': 0.0, 'fmeasure': 0.0}\n",
    "}\n",
    "\n",
    "# Loop\n",
    "for pred, ref in tqdm(zip(predictions, ref_reasonings), total=len(predictions), desc=\"Computing ROUGE\"):\n",
    "    pred_reasoning = pred[\"reasoning\"]\n",
    "    scores = scorer.score(ref, pred_reasoning)\n",
    "    \n",
    "    for metric in rouge_scores.keys():\n",
    "        rouge_scores[metric]['precision'] += scores[metric].precision\n",
    "        rouge_scores[metric]['recall'] += scores[metric].recall\n",
    "        rouge_scores[metric]['fmeasure'] += scores[metric].fmeasure\n",
    "\n",
    "# Average\n",
    "n = len(predictions)\n",
    "for metric in rouge_scores.keys():\n",
    "    for key in rouge_scores[metric].keys():\n",
    "        rouge_scores[metric][key] /= n\n",
    "\n",
    "# Print\n",
    "print(\"\\nROUGE Scores:\")\n",
    "for metric, scores in rouge_scores.items():\n",
    "    print(f\"\\n{metric}:\")\n",
    "    for key, value in scores.items():\n",
    "        print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab10d113",
   "metadata": {},
   "source": [
    "# Calculate sacrebleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cdaf7636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating BLEU score on reasoning...\n",
      "\n",
      "SacreBLEU Score: 21.1412\n"
     ]
    }
   ],
   "source": [
    "# Calculate sacrebleu score\n",
    "import sacrebleu\n",
    "\n",
    "# Prepare references and predictions for sacrebleu\n",
    "pred_texts = [pred['reasoning'] for pred in predictions] \n",
    "refs_for_sacrebleu = [[ref] for ref in ref_reasonings]\n",
    "\n",
    "# Calculate sacrebleu\n",
    "print(\"\\nCalculating BLEU score on reasoning...\")\n",
    "bleu = sacrebleu.corpus_bleu(pred_texts, refs_for_sacrebleu)\n",
    "print(f\"\\nSacreBLEU Score: {bleu.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340ec03",
   "metadata": {},
   "source": [
    "# Calculate Exact Match Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8839ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exact Match Score: 0.4700\n"
     ]
    }
   ],
   "source": [
    "# Calculate Exact Match Score\n",
    "exact_match_count = 0\n",
    "\n",
    "for pred, ref_ans in zip(predictions, references):\n",
    "    if pred['answer'].strip() == ref_ans.split('###')[-1].strip():\n",
    "        exact_match_count += 1\n",
    "\n",
    "exact_match_score = exact_match_count / len(predictions)\n",
    "\n",
    "print(f\"\\nExact Match Score: {exact_match_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "577176ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95d1cd",
   "metadata": {},
   "source": [
    "# Save all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e329f269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1.7495\n",
      "SacreBLEU Score: 21.1412\n",
      "\n",
      "ROUGE Scores Summary:\n",
      "rouge1 F1: 0.5971\n",
      "rouge2 F1: 0.3259\n",
      "rougeL F1: 0.4308\n",
      "\n",
      "Exact Match Score: 0.4700\n",
      "\n",
      "Metrics saved to ./logs/qwen-2.5-3b-instruct-math-qa.json\n"
     ]
    }
   ],
   "source": [
    "# Save all metrics\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a summary dictionary of all metrics\n",
    "evaluation_metrics = {\n",
    "    'perplexity': perplexity,\n",
    "    'sacrebleu': bleu.score,\n",
    "    'rouge_scores': rouge_scores,\n",
    "    'exact_match_score': exact_match_score,\n",
    "}\n",
    "\n",
    "# Prepare metrics with timestamp for saving\n",
    "metrics_filename = \"./logs/qwen-2.5-3b-instruct-math-qa.json\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "metrics_to_save = {\n",
    "    'timestamp': timestamp,\n",
    "    'model_name': \"./logs/qwen-2.5-3b-instruct-math-qa\",\n",
    "    'metrics': evaluation_metrics\n",
    "}\n",
    "\n",
    "# Print summary before saving\n",
    "print(f\"Perplexity: {evaluation_metrics['perplexity']:.4f}\")\n",
    "print(f\"SacreBLEU Score: {evaluation_metrics['sacrebleu']:.4f}\")\n",
    "print(\"\\nROUGE Scores Summary:\")\n",
    "for metric, scores in evaluation_metrics['rouge_scores'].items():\n",
    "    print(f\"{metric} F1: {scores['fmeasure']:.4f}\")\n",
    "print(f\"\\nExact Match Score: {evaluation_metrics['exact_match_score']:.4f}\")\n",
    "\n",
    "# Save to file\n",
    "with open(metrics_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics_to_save, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nMetrics saved to {metrics_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
