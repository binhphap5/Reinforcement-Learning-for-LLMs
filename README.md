# ðŸ¤– Reinforcement Learning for Large Language Models (LLMs)

This repository combines two independent research directions that use **Reinforcement Learning (RL)** to enhance the capabilities and alignment of Large Language Models (LLMs).

---

## ðŸ§  Structure

```bash
.
â”œâ”€â”€ LLMs_reasoning/        # Enhancing LLM reasoning with GRPO
â”‚   â””â”€â”€ README.md          # Detailed explanation of GRPO-based approach
â”‚
â”œâ”€â”€ LLMs_preference/       # Aligning LLMs to user preferences with PPO & DPO
â”‚   â””â”€â”€ README.md          # Detailed explanation of PPO and DPO training
â”‚
â””â”€â”€ README.md              # (You are here) High-level summary of the entire project
